---
title: "Classification : concepts et algorithmes de base"
description: "D√©couvrez les fondamentaux de la classification en apprentissage supervis√©"
difficulty: "intermediate"
estimatedTime: "45 minutes"
keywords: ["classification", "apprentissage supervis√©", "algorithmes", "features"]
---

# Classification : concepts et algorithmes de base

## üéØ Objectifs d'apprentissage

√Ä la fin de cette le√ßon, vous serez capable de :
- ‚úÖ Comprendre le probl√®me de classification et ses variants
- ‚úÖ Distinguer classification binaire et multi-classes
- ‚úÖ Identifier les composantes d'un probl√®me de classification
- ‚úÖ Pr√©parer des donn√©es pour l'entra√Ænement

---

## üîç Qu'est-ce que la classification ?

<div data-mermaid="classification-concept">

```mermaid
graph TD
    A[Donn√©es d'entr√©e<br/>Features X] --> B[Mod√®le de<br/>Classification]
    B --> C[Pr√©diction<br/>Classe ≈∑]
    
    D[Donn√©es √©tiquet√©es<br/>X, y] --> E[Entra√Ænement]
    E --> B
    
    F[Nouvelles donn√©es<br/>X_new] --> B
    B --> G[Classe pr√©dite<br/>≈∑_new]
    
    style A fill:#e1f5fe
    style C fill:#c8e6c9
    style D fill:#fff3e0
    style G fill:#c8e6c9
```

</div>

**La classification** est une t√¢che d'apprentissage supervis√© o√π l'objectif est de **pr√©dire une cat√©gorie** (classe) pour de nouvelles observations, bas√©e sur des exemples d'entra√Ænement.

### Types de classification

#### üî¥ Classification binaire
- **2 classes** seulement (ex: spam/non-spam, malade/sain)
- Sortie : 0 ou 1, vrai/faux

#### üåà Classification multi-classes
- **Plus de 2 classes** mutuellement exclusives
- Exemple : reconnaissance de chiffres (0-9), classification d'images (chat, chien, oiseau)

#### üè∑Ô∏è Classification multi-labels
- **Plusieurs √©tiquettes** possibles simultan√©ment
- Exemple : tags d'articles (tech, science, actualit√©)

---

## üìä Anatomie d'un probl√®me de classification

### 1. Features (caract√©ristiques)

Les **variables d'entr√©e** qui d√©crivent nos observations :

```mermaid
graph LR
    subgraph "Email Spam Detection"
        A[Nombre de mots] --> D[Mod√®le]
        B[Pr√©sence de '$'] --> D
        C[Longueur du sujet] --> D
        D --> E[Spam/Ham]
    end
    
    style A fill:#bbdefb
    style B fill:#bbdefb
    style C fill:#bbdefb
    style E fill:#c8e6c9
```

**Types de features :**
- **Num√©riques** : √¢ge, salaire, taille
- **Cat√©gorielles** : couleur, ville, profession
- **Binaires** : oui/non, pr√©sent/absent
- **Textuelles** : mots, phrases (n√©cessitent preprocessing)

### 2. Labels (√©tiquettes)

Les **classes cibles** que nous voulons pr√©dire :

| Probl√®me | Classes | Type |
|----------|---------|------|
| Diagnostic m√©dical | Sain, Malade | Binaire |
| Reconnaissance d'images | Chat, Chien, Oiseau | Multi-classes |
| Analyse de sentiment | Positif, Neutre, N√©gatif | Multi-classes |

### 3. Dataset structure

```python
# Structure typique d'un dataset de classification
import pandas as pd

# Exemple : pr√©diction de prix immobilier (√©lev√©/bas)
data = {
    'surface': [80, 120, 60, 150],      # Feature num√©rique
    'ville': ['Paris', 'Lyon', 'Nice', 'Paris'],  # Feature cat√©gorielle  
    'balcon': [1, 0, 1, 1],             # Feature binaire
    'prix_eleve': [1, 1, 0, 1]          # Label cible
}
df = pd.DataFrame(data)
```

---

## üîß Pipeline de classification

### √âtapes essentielles

```mermaid
flowchart TD
    A[üìä Collecte des donn√©es] --> B[üßπ Preprocessing]
    B --> C[üìà Exploration des donn√©es]
    C --> D[‚öôÔ∏è Feature Engineering]
    D --> E[üìÇ Split train/test]
    E --> F[ü§ñ Entra√Ænement du mod√®le]
    F --> G[üìä √âvaluation]
    G --> H{Performance OK?}
    H -->|Non| I[üîß Ajustement]
    I --> F
    H -->|Oui| J[üöÄ D√©ploiement]
    
    style A fill:#e3f2fd
    style F fill:#f3e5f5
    style G fill:#e8f5e8
    style J fill:#fff3e0
```

### 1. Preprocessing des donn√©es

#### Gestion des valeurs manquantes
```python
# Strat√©gies courantes
df.fillna(df.mean())  # Moyenne pour num√©riques
df.fillna(df.mode().iloc[0])  # Mode pour cat√©gorielles
df.dropna()  # Suppression (si peu de valeurs manquantes)
```

#### Encoding des variables cat√©gorielles
```python
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Label encoding (ordinales)
le = LabelEncoder()
df['ville_encoded'] = le.fit_transform(df['ville'])

# One-hot encoding (nominales)
df_encoded = pd.get_dummies(df, columns=['ville'])
```

#### Normalisation
```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Standardisation (Œº=0, œÉ=1)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Normalisation (0-1)
minmax = MinMaxScaler()
X_normalized = minmax.fit_transform(X)
```

### 2. Split des donn√©es

```python
from sklearn.model_selection import train_test_split

# Division classique 80/20
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42,
    stratify=y  # Pr√©serve la distribution des classes
)
```

---

## üé≤ Premiers algorithmes

### 1. K-Nearest Neighbors (k-NN)

**Principe** : Classer selon les k voisins les plus proches

```mermaid
graph TD
    A[Point √† classer] --> B[Calculer distances]
    B --> C[Trouver k voisins plus proches]
    C --> D[Vote majoritaire]
    D --> E[Classe pr√©dite]
    
    subgraph "Exemple k=3"
        F[‚óè Point inconnu] 
        G[üî¥ Classe A: 2 voisins]
        H[üîµ Classe B: 1 voisin]
        I[‚Üí Pr√©diction: Classe A]
    end
```

**Avantages :**
- Simple √† comprendre et impl√©menter
- Pas d'hypoth√®se sur la distribution des donn√©es
- Fonctionne bien avec peu de donn√©es

**Inconv√©nients :**
- Co√ªteux en calcul (distance √† tous les points)
- Sensible √† la dimension (curse of dimensionality)
- Sensible aux donn√©es bruit√©es

### 2. Na√Øve Bayes

**Principe** : Application du th√©or√®me de Bayes avec hypoth√®se d'ind√©pendance

P(classe|features) = P(features|classe) √ó P(classe) / P(features)

**Types principaux :**
- **Gaussian NB** : features continues
- **Multinomial NB** : comptages (texte)
- **Bernoulli NB** : features binaires

**Avantages :**
- Tr√®s rapide
- Fonctionne bien avec peu de donn√©es
- Excellent pour la classification de texte

**Inconv√©nients :**
- Hypoth√®se d'ind√©pendance souvent irr√©aliste
- Performance limit√©e si hypoth√®se viol√©e

---

## üìà M√©triques de base

### Pour classification binaire

```mermaid
graph TD
    subgraph "Matrice de confusion"
        A[True Positive<br/>TP] --> E[Actual: Positive<br/>Predicted: Positive]
        B[False Positive<br/>FP] --> F[Actual: Negative<br/>Predicted: Positive]
        C[False Negative<br/>FN] --> G[Actual: Positive<br/>Predicted: Negative]
        D[True Negative<br/>TN] --> H[Actual: Negative<br/>Predicted: Negative]
    end
```

**M√©triques essentielles :**

- **Accuracy** = (TP + TN) / (TP + TN + FP + FN)
- **Precision** = TP / (TP + FP) - "Parmi mes pr√©dictions positives, combien sont correctes ?"
- **Recall** = TP / (TP + FN) - "Parmi les cas positifs r√©els, combien j'en d√©tecte ?"
- **F1-Score** = 2 √ó (Precision √ó Recall) / (Precision + Recall)

### Choix de m√©trique selon le contexte

| Contexte | M√©trique privil√©gi√©e | Raison |
|----------|---------------------|---------|
| D√©tection de fraude | **Recall** | Ne pas manquer de vrais cas |
| Diagnostic m√©dical | **Recall** | Ne pas manquer de malades |
| Filtrage spam | **Precision** | √âviter faux positifs |
| Syst√®me √©quilibr√© | **F1-Score** | Compromis precision/recall |

---

## üí° Bonnes pratiques

### 1. Exploration des donn√©es

```python
# Distribution des classes
y.value_counts()
y.value_counts(normalize=True)

# Corr√©lations entre features
df.corr()

# Statistiques descriptives
df.describe()
```

### 2. Gestion du d√©s√©quilibre de classes

```python
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE

# Sous-√©chantillonnage de la classe majoritaire
df_minority = df[df.target == 0]
df_majority = df[df.target == 1]
df_majority_downsampled = resample(df_majority, n_samples=len(df_minority))

# Sur-√©chantillonnage avec SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
```

### 3. Validation crois√©e

```python
from sklearn.model_selection import cross_val_score, StratifiedKFold

# Validation crois√©e stratifi√©e
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=cv, scoring='f1')
print(f"F1-Score moyen: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")
```

---

## üéØ R√©capitulatif

**Points cl√©s √† retenir :**

1. **Classification = pr√©diction de cat√©gories** √† partir d'exemples √©tiquet√©s
2. **Preprocessing crucial** : gestion des valeurs manquantes, encoding, normalisation
3. **k-NN et Na√Øve Bayes** : algorithmes simples mais efficaces pour d√©buter
4. **M√©triques vari√©es** : choisir selon le contexte m√©tier
5. **Validation rigoureuse** : train/test split + validation crois√©e

**Prochaines √©tapes :**
- Algorithmes plus sophistiqu√©s (arbres, SVM, r√©seaux de neurones)
- Techniques d'optimisation des hyperparam√®tres
- Feature selection et engineering avanc√©

---

## üîó Pour aller plus loin

- **Datasets d'entra√Ænement** : UCI ML Repository, Kaggle, scikit-learn datasets
- **Librairies Python** : scikit-learn, pandas, numpy
- **Visualisation** : matplotlib, seaborn, plotly
- **M√©triques avanc√©es** : ROC-AUC, pr√©cision-rappel curves