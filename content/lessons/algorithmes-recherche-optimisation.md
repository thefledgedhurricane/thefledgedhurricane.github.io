---
title: "Algorithmes de recherche et optimisation"
description: "Exploration approfondie des algorithmes de recherche, heuristiques et techniques d'optimisation en intelligence artificielle"
difficulty: "intermediate"
estimatedTime: "360 minutes"
keywords: ["algorithmes", "recherche", "optimisation", "heuristiques", "A*", "minimax", "mÃ©ta-heuristiques"]
---

# Algorithmes de recherche et optimisation

## Introduction aux problÃ¨mes de recherche

La recherche est l'un des piliers fondamentaux de l'intelligence artificielle. Dans de nombreux domaines, nous cherchons Ã  trouver une solution optimale ou satisfaisante parmi un ensemble de possibilitÃ©s, souvent trÃ¨s vaste.

### ğŸ® Les diffÃ©rents types de problÃ¨mes : Comme dans un jeu vidÃ©o !

Imaginez que rÃ©soudre un problÃ¨me, c'est comme jouer Ã  un jeu vidÃ©o oÃ¹ vous devez aller du point A au point B. Il y a diffÃ©rents types de "jeux" selon la situation !

### ğŸ—ºï¸ Type 1 : Les problÃ¨mes de "navigation" (Recherche d'Ã©tat)

**L'idÃ©e simple :** Vous Ãªtes quelque part et vous voulez aller ailleurs. Ã€ chaque Ã©tape, vous pouvez faire certaines actions.

```mermaid
graph TD
    subgraph "ğŸ® Comme dans un jeu vidÃ©o"
        A[ğŸ  Chez moi] --> B[ğŸš¶ Je marche]
        A --> C[ğŸš— Je prends la voiture]
        B --> D[ğŸª Magasin]
        C --> D
        D --> E[ğŸ¯ Destination finale]
    end
    
    style A fill:#e3f2fd
    style E fill:#c8e6c9
```

**Les 4 Ã©lÃ©ments magiques :**

1. **ğŸ  OÃ¹ je suis maintenant** (l'Ã©tat de dÃ©part)
   - Exemple : "Je suis Ã  la maison"

2. **ğŸ¯ OÃ¹ je veux arriver** (l'Ã©tat final)
   - Exemple : "Je veux Ãªtre au cinÃ©ma"

3. **ğŸš¶ Ce que je peux faire** (les actions possibles)
   - Exemple : marcher, prendre le bus, appeler un taxi

4. **ğŸ’° Combien Ã§a coÃ»te** (le prix de chaque action)
   - Exemple : marcher = gratuit, bus = 2â‚¬, taxi = 15â‚¬

### ğŸ“± Exemple 1 : Votre GPS qui vous guide

**La situation :** Vous voulez aller de votre maison au restaurant.

```mermaid
graph LR
    subgraph "ğŸ—ºï¸ Trajet GPS"
        A[ğŸ  Maison<br/>Rue de la Paix] --> B[ğŸš¦ Feu rouge<br/>Avenue Mozart]
        B --> C[â¬…ï¸ Tournez Ã  gauche<br/>Rue du Commerce]
        C --> D[ğŸ½ï¸ Restaurant<br/>Place du MarchÃ©]
    end
```

**Ce que fait votre GPS :**
- **Point de dÃ©part** : Votre adresse actuelle
- **Point d'arrivÃ©e** : L'adresse du restaurant
- **Actions possibles** : Tout droit, tourner Ã  gauche, tourner Ã  droite, faire demi-tour
- **CritÃ¨re** : Le chemin le plus rapide (ou le plus court)

### ğŸ§© Exemple 2 : RÃ©soudre un puzzle

**La situation :** Vous avez un puzzle mÃ©langÃ© et vous voulez le remettre en ordre.

```mermaid
graph TD
    subgraph "ğŸ§© Puzzle Ã  rÃ©soudre"
        A["Ã‰tat mÃ©langÃ©<br/>ğŸ˜µ 2 1 3<br/>ğŸ˜µ 4 _ 5<br/>ğŸ˜µ 6 7 8"] 
        A --> B["Une action<br/>â†•ï¸ Bouger une piÃ¨ce"]
        B --> C["Ã‰tat final<br/>ğŸ˜Š 1 2 3<br/>ğŸ˜Š 4 5 6<br/>ğŸ˜Š 7 8 _"]
    end
    
    style A fill:#ffebee
    style C fill:#e8f5e8
```

**Ce qu'il faut faire :**
- **Ã‰tat de dÃ©part** : Puzzle mÃ©langÃ©
- **Ã‰tat final** : Puzzle rÃ©solu
- **Actions possibles** : Faire glisser une piÃ¨ce dans l'espace vide
- **Objectif** : RÃ©soudre en un minimum de mouvements

### ğŸ° Exemple 3 : Jeu vidÃ©o d'aventure

**La situation :** Vous Ãªtes un hÃ©ros qui doit sauver la princesse.

```mermaid
flowchart LR
    A[ğŸƒ HÃ©ros au village] --> B{ğŸ—ï¸ ClÃ© trouvÃ©e ?}
    B -->|Non| C[ğŸ” Chercher la clÃ©]
    C --> B
    B -->|Oui| D[ğŸšª Ouvrir porte chÃ¢teau]
    D --> E[âš”ï¸ Combattre dragon]
    E --> F[ğŸ‘¸ Sauver princesse]
```

**Les rÃ¨gles du jeu :**
- **Ã‰tat de dÃ©part** : HÃ©ros au village, pas de clÃ©, princesse prisonniÃ¨re
- **Ã‰tat final** : Princesse sauvÃ©e
- **Actions possibles** : Se dÃ©placer, ramasser objets, combattre, utiliser objets
- **Contraintes** : Il faut la clÃ© pour ouvrir la porte !

### ğŸ¯ Pourquoi c'est important de comprendre Ã§a ?

**Tous ces problÃ¨mes ont la mÃªme structure :**

1. **ğŸ¬ Un point de dÃ©part** (oÃ¹ on est maintenant)
2. **ğŸ Un ou plusieurs points d'arrivÃ©e** (oÃ¹ on veut aller)
3. **ğŸ® Des actions possibles** (ce qu'on peut faire Ã  chaque Ã©tape)
4. **ğŸ“ Un critÃ¨re de qualitÃ©** (qu'est-ce qui fait une "bonne" solution)

**La magie de l'informatique :** Une fois qu'on a traduit notre problÃ¨me dans cette forme, on peut utiliser les mÃªmes algorithmes pour :
- ğŸ—ºï¸ Calculer un itinÃ©raire
- ğŸ§© RÃ©soudre un puzzle
- ğŸ¤– Faire bouger un robot
- ğŸ² Gagner Ã  un jeu
- ğŸ“Š Optimiser un planning

**Le message principal :** MÃªme si les problÃ¨mes semblent trÃ¨s diffÃ©rents, ils suivent tous le mÃªme schÃ©ma ! C'est pour Ã§a qu'on peut utiliser les mÃªmes "recettes" (algorithmes) pour les rÃ©soudre.

#### 2. Recherche combinatoire : RÃ©soudre des puzzles gÃ©ants

**L'idÃ©e simple** : Imaginez que vous devez choisir la meilleure option parmi des millions de possibilitÃ©s. C'est exactement ce qu'est la recherche combinatoire !

```mermaid
graph LR
    A[ğŸ¯ ProblÃ¨me] --> B[ğŸ“Š Millions de solutions possibles]
    B --> C[ğŸ” Trouver LA meilleure]
    C --> D[âœ… Solution optimale]
```

**Pourquoi c'est difficile ?**
- Il y a trop de possibilitÃ©s Ã  vÃ©rifier une par une
- Le nombre de solutions explose trÃ¨s vite (10 villes = 181,000 trajets possibles !)
- Il faut Ãªtre malin pour ne pas perdre des annÃ©es Ã  calculer

### ğŸš— Exemple 1 : Le livreur et ses tournÃ©es (TSP)

**Le problÃ¨me en franÃ§ais simple :**
Un livreur doit visiter 5 clients et revenir Ã  son dÃ©pÃ´t. Quel est le chemin le plus court ?

```mermaid
graph TD
    subgraph "5 clients Ã  visiter"
        Depot[ğŸ¢ DÃ©pÃ´t]
        A[ğŸ‘¤ Client A]
        B[ğŸ‘¤ Client B] 
        C[ğŸ‘¤ Client C]
        D[ğŸ‘¤ Client D]
        E[ğŸ‘¤ Client E]
    end
    
    Depot -.->|12km| A
    Depot -.->|8km| B
    A -.->|5km| C
    B -.->|7km| D
    C -.->|3km| E
```

**Pourquoi c'est compliquÃ© :**
- Avec 5 clients, il y a 120 trajets diffÃ©rents possibles
- Avec 10 clients, il y a 3,628,800 trajets !
- Avec 20 clients, votre ordinateur mettrait des milliards d'annÃ©es

**Solutions pratiques :**
1. **MÃ©thode du plus proche voisin** : "Je vais toujours au client le plus proche"
   - âœ… TrÃ¨s rapide Ã  calculer
   - âŒ Pas forcÃ©ment le meilleur chemin

2. **AmÃ©lioration par Ã©changes** : "J'essaie d'Ã©changer 2 clients dans mon trajet"
   - âœ… AmÃ©liore une solution existante
   - âœ… Marche bien en pratique

**UtilisÃ© dans la vraie vie :**
- ğŸ“¦ Amazon pour optimiser les livraisons
- ğŸš› Entreprises de transport
- ğŸ”§ Maintenance d'Ã©quipements
- ğŸ­ Robots dans les usines

### ğŸ¨ Exemple 2 : Colorier une carte sans conflit

**Le problÃ¨me en franÃ§ais simple :**
Vous devez colorier une carte oÃ¹ chaque rÃ©gion voisine doit avoir une couleur diffÃ©rente. Combien de couleurs minimum vous faut-il ?

```mermaid
graph TD
    subgraph "Carte Ã  colorier"
        A[France] --- B[Espagne]
        A --- C[Allemagne]
        A --- D[Italie]
        B --- E[Portugal]
        C --- F[Pologne]
    end
    
    subgraph "Solution avec 3 couleurs"
        G[ğŸŸ¥ France = Rouge<br/>ğŸŸ¦ Espagne = Bleu<br/>ğŸŸ© Allemagne = Vert<br/>ğŸŸ¦ Italie = Bleu<br/>ğŸŸ¥ Portugal = Rouge<br/>ğŸŸ© Pologne = Vert]
    end
```

**RÃ¨gle simple :** Deux pays qui se touchent ne peuvent pas avoir la mÃªme couleur.

**MÃ©thode de rÃ©solution :**
1. Prendre le premier pays â†’ lui donner la couleur 1
2. Prendre le pays suivant â†’ lui donner la premiÃ¨re couleur possible
3. RÃ©pÃ©ter jusqu'Ã  la fin

**UtilisÃ© dans la vraie vie :**
- ğŸ“… Planning des cours (2 cours au mÃªme crÃ©neau = conflit)
- ğŸ“¡ Attribution des frÃ©quences radio
- ğŸ¥ Planning des mÃ©decins dans un hÃ´pital
- ğŸ® Sudoku (version complexe du coloriage)

### âš™ï¸ Exemple 3 : Organiser des tÃ¢ches sur des machines

**Le problÃ¨me en franÃ§ais simple :**
Vous avez 4 tÃ¢ches Ã  faire sur 2 machines. Comment les organiser pour finir le plus vite possible ?

```mermaid
gantt
    title Mauvaise organisation vs Bonne organisation
    dateFormat X
    axisFormat %s
    
    section Machine 1 (mauvais)
    TÃ¢che A (3h) :0, 3
    TÃ¢che C (2h) :3, 2
    Attente      :5, 1
    
    section Machine 2 (mauvais)
    Attente      :0, 2
    TÃ¢che B (4h) :2, 4
    
    section Machine 1 (bon)
    TÃ¢che A (3h) :crit, 6, 3
    TÃ¢che D (1h) :9, 1
    
    section Machine 2 (bon)  
    TÃ¢che B (4h) :6, 4
    TÃ¢che C (2h) :10, 2
```

**L'objectif :** Finir toutes les tÃ¢ches le plus rapidement possible.

**StratÃ©gies simples :**
1. **Les plus longues d'abord** : Commence par les tÃ¢ches qui prennent le plus de temps
2. **Ã‰quilibrer les machines** : Ã‰vite qu'une machine soit inactive trop longtemps
3. **Respecter les prioritÃ©s** : Certaines tÃ¢ches doivent Ãªtre faites avant d'autres

**UtilisÃ© dans la vraie vie :**
- ğŸ­ ChaÃ®nes de production en usine
- ğŸ’» RÃ©partition des calculs sur plusieurs processeurs
- ğŸ¥ Planning des opÃ©rations chirurgicales
- ğŸš› Organisation des Ã©quipes de transport

### ğŸ¯ Le message principal

**Ces problÃ¨mes ont tous le mÃªme dÃ©fi :**
- Beaucoup trop de possibilitÃ©s pour tout essayer
- Il faut trouver des "raccourcis intelligents"
- On accepte parfois une trÃ¨s bonne solution plutÃ´t que LA solution parfaite

**Techniques gÃ©nÃ©rales :**
1. **Commencer par une solution simple** (mÃªme si elle n'est pas parfaite)
2. **L'amÃ©liorer petit Ã  petit** en faisant de petits changements
3. **Utiliser son bon sens** et des rÃ¨gles pratiques
4. **ArrÃªter quand c'est assez bien** plutÃ´t que de chercher la perfection

C'est exactement ce que font les algorithmes modernes : ils sont malins plutÃ´t que brutaux !

## ğŸ§­ Maintenant, dÃ©couvrons les "recettes" concrÃ¨tes !

Bon, maintenant que vous comprenez le principe gÃ©nÃ©ral (partir d'un Ã©tat, faire des actions, arriver au but), il est temps de voir **comment** l'ordinateur explore toutes ces possibilitÃ©s.

**Imaginez que vous cherchez vos clÃ©s perdues dans votre maison** ğŸ”‘

Il y a plusieurs stratÃ©gies possibles :
1. **ğŸŒŠ MÃ©thode "vague d'eau"** : Chercher piÃ¨ce par piÃ¨ce, Ã©tage par Ã©tage
2. **â¬‡ï¸ MÃ©thode "tunnel"** : Fouiller complÃ¨tement une piÃ¨ce avant de passer Ã  la suivante
3. **ğŸ§­ MÃ©thode "GPS"** : Utiliser des indices pour aller directement vers la bonne piÃ¨ce

Ces 3 approches correspondent exactement aux 3 grandes familles d'algorithmes de recherche !

### ğŸ¯ Pourquoi commencer par les algorithmes "aveugles" ?

Les algorithmes **"non informÃ©s"** (ou "aveugles") ne connaissent rien sur le problÃ¨me Ã  part :
- âœ… L'Ã©tat actuel
- âœ… Les actions possibles  
- âœ… Comment reconnaÃ®tre la solution

Ils n'ont **aucune information** sur la direction Ã  prendre. C'est comme chercher ses clÃ©s **sans aucun indice** !

**Pourquoi apprendre Ã§a en premier ?**
- ğŸ¯ Plus simple Ã  comprendre
- ğŸ§± Base de tous les autres algorithmes
- ğŸ’¡ Montre clairement les avantages/inconvÃ©nients de chaque approche
- ğŸ› ï¸ UtilisÃ©s en pratique dans de nombreux cas

---

## ğŸŒŠ Algorithme 1 : La "vague d'eau" (Recherche en largeur - BFS)

### ğŸ  L'analogie simple : Chercher ses clÃ©s comme une vague

**Imaginez que vous cherchez vos clÃ©s perdues dans votre maison :**

```mermaid
graph TD
    subgraph "ğŸ  Ma maison"
        A[ğŸšª Je commence<br/>Ã  l'entrÃ©e] 
        A --> B[ğŸ›‹ï¸ Salon]
        A --> C[ğŸ½ï¸ Cuisine]  
        A --> D[ğŸš¿ Salle de bain]
        B --> E[ğŸ“º DerriÃ¨re TV]
        B --> F[ğŸ›‹ï¸ Sous coussins]
        C --> G[â„ï¸ Dans frigo]
        C --> H[ğŸ—„ï¸ Tiroir cuisine]
    end
```

**La stratÃ©gie "vague d'eau" :**
1. ğŸ¯ Je regarde d'abord **toutes** les piÃ¨ces du rez-de-chaussÃ©e
2. ğŸ¯ Puis **toutes** les piÃ¨ces du 1er Ã©tage  
3. ğŸ¯ Puis **toutes** les piÃ¨ces du 2Ã¨me Ã©tage
4. âœ… Je trouve forcÃ©ment mes clÃ©s !

### ğŸ¤” Pourquoi cette mÃ©thode est intelligente ?

**âœ… Avantages :**
- **ğŸ“ Distance minimale garantie** : Si mes clÃ©s sont au rez-de-chaussÃ©e, je ne perds pas de temps Ã  monter au 2Ã¨me Ã©tage !
- **âœ… SuccÃ¨s garanti** : Je finirai forcÃ©ment par les trouver
- **ğŸ“Š SystÃ©matique** : Je ne peux pas "oublier" une piÃ¨ce

**âŒ InconvÃ©nients :**
- **ğŸ§  MÃ©moire** : Je dois me rappeler de TOUTES les piÃ¨ces dÃ©jÃ  visitÃ©es
- **â±ï¸ Lenteur** : Si mes clÃ©s sont au 3Ã¨me Ã©tage, Ã§a va prendre du temps...

### ğŸ” Comment Ã§a marche concrÃ¨tement ?

```mermaid
flowchart LR
    subgraph "ğŸ¯ Ã‰tape par Ã©tape"
        A[ğŸ“ Liste des piÃ¨ces Ã  explorer] --> B[ğŸ‘€ Je prends la premiÃ¨re piÃ¨ce]
        B --> C{ğŸ”‘ ClÃ©s trouvÃ©es ?}
        C -->|âœ… Oui| D[ğŸ‰ TerminÃ© !]
        C -->|âŒ Non| E[ğŸ“ J'ajoute les piÃ¨ces voisines Ã  ma liste]
        E --> B
    end
```

**Exemple concret :**
- **Tour 1** : J'explore l'entrÃ©e â†’ J'ajoute salon, cuisine, salle de bain Ã  ma liste
- **Tour 2** : J'explore salon â†’ J'ajoute derriÃ¨re TV, sous coussins Ã  ma liste  
- **Tour 3** : J'explore cuisine â†’ J'ajoute frigo, tiroir Ã  ma liste
- **Tour 4** : J'explore salle de bain â†’ Mes clÃ©s sont lÃ  ! ğŸ‰

### ğŸ® Pourquoi on appelle Ã§a "Breadth-First Search" (BFS) ?

- **"Breadth"** = Largeur â†’ On explore en **largeur** d'abord
- **"First"** = D'abord â†’ Avant d'aller plus **profond**

C'est comme une vague qui s'Ã©tend de plus en plus loin !

---

### ğŸ’» Version technique pour les curieux

Maintenant que vous comprenez le principe, voici comment l'ordinateur fait Ã§a prÃ©cisÃ©ment :

### 1. Recherche en largeur (BFS) - Analyse approfondie

```mermaid
flowchart TD
    A["BFS: Breadth-First Search"] --> B[StratÃ©gie]
    A --> C[Structure de donnÃ©es]
    A --> D[PropriÃ©tÃ©s]
    
    B --> B1["Explorer niveau par niveau<br/>FIFO - First In First Out"]
    C --> C1["File/Queue<br/>Ensemble des visitÃ©s"]
    D --> D1["ComplÃ¨te: OUI<br/>Optimale: OUI si coÃ»t uniforme<br/>Temps: O(b exposant d)<br/>Espace: O(b exposant d)"]
    
    style A fill:#e1f5fe
    style D1 fill:#fff3e0
```

**Principe dÃ©taillÃ©** : Explorer systÃ©matiquement niveau par niveau depuis la racine.

**Avantages spÃ©cifiques** :

- **ComplÃ©tude garantie** : Trouve toujours une solution si elle existe (espace fini)
- **OptimalitÃ©** : Trouve la solution la plus courte en nombre d'Ã©tapes (coÃ»t uniforme)
- **PrÃ©visibilitÃ©** : Comportement dÃ©terministe et analysable
- **ParallÃ©lisation** : Facilement parallÃ©lisable par niveau

**InconvÃ©nients et limitations** :

- **Explosion mÃ©moire** : O(b^d) peut devenir prohibitif rapidement
- **Lenteur en profondeur** : Inefficace si la solution est trÃ¨s profonde
- **CoÃ»t uniforme requis** : Non optimal si les actions ont des coÃ»ts diffÃ©rents
- **Pas de guidage** : N'utilise aucune information sur la direction du but

**Cas d'usage optimaux** :

- **Puzzles simples** : 8-puzzle, 15-puzzle avec solutions peu profondes
- **Graphes sociaux** : Trouver le plus court chemin entre personnes
- **RÃ©seaux** : Routage avec nombre minimal de sauts
- **Jeux** : RÃ©solution de niveaux avec solutions courtes garanties

**ProblÃ¨mes frÃ©quents** :

- **Out of Memory** : Avec facteur de branchement > 10 et profondeur > 6
- **Thrashing** : AccÃ¨s mÃ©moire chaotiques avec grandes structures
- **Redondance** : Exploration d'Ã©tats Ã©quivalents par diffÃ©rents chemins

**Optimisations pratiques** :

```python
# Optimisation mÃ©moire avec gÃ©nÃ©rateurs
def bfs_optimized(problem):
    visited = set()
    queue = deque([initial_node])
    
    # Ã‰viter les doublons dans la queue mÃªme
    in_queue = {initial_state}
    
    while queue:
        node = queue.popleft()
        in_queue.remove(node.state)
        
        if node.state in visited:
            continue
            
        visited.add(node.state)
        # ... rest of algorithm
```

### 2. Recherche en profondeur (DFS) - Analyse approfondie

```mermaid
flowchart TD
    A["DFS: Depth-First Search"] --> B[StratÃ©gie]
    A --> C[Structure de donnÃ©es] 
    A --> D[Variantes]
    A --> E[PropriÃ©tÃ©s]
    
    B --> B1["Explorer profondÃ©ment<br/>LIFO - Last In First Out"]
    C --> C1["Pile/Stack<br/>RÃ©cursion naturelle"]
    D --> D1["DFS standard<br/>DFS limitÃ©e<br/>Iterative Deepening"]
    E --> E1["ComplÃ¨te: NON (dans infini)<br/>Optimale: NON<br/>Temps: O(b exposant m)<br/>Espace: O(b x m)"]
    
    style A fill:#f3e5f5
    style E1 fill:#ffebee
```

**Principe dÃ©taillÃ©** : Explorer une branche complÃ¨tement avant de revenir en arriÃ¨re (backtracking).

**Avantages spÃ©cifiques** :

- **MÃ©moire linÃ©aire** : O(bm) beaucoup plus gÃ©rable que BFS
- **Solutions profondes** : Excellente pour problÃ¨mes avec solutions loin de la racine
- **ImplÃ©mentation simple** : RÃ©cursion naturelle, code Ã©lÃ©gant
- **Bon pour Ã©numÃ©ration** : Parcourir tous les Ã©tats possibles

**InconvÃ©nients et limitations** :

- **Cycles infinis** : Peut boucler indÃ©finiment sans dÃ©tection de cycles
- **Non optimale** : Trouve une solution, pas forcÃ©ment la meilleure
- **IncomplÃ¨te** : Peut ne jamais trouver de solution (espaces infinis)
- **DÃ©pendance Ã  l'ordre** : Performance trÃ¨s variable selon ordre d'exploration

**Cas d'usage optimaux** :

- **Backtracking** : N-reines, Sudoku, coloration de graphes
- **GÃ©nÃ©ration exhaustive** : Toutes les permutations, combinaisons
- **Arbres de dÃ©cision** : Quand toutes les branches doivent Ãªtre explorÃ©es
- **DÃ©tection de cycles** : Dans les graphes (avec marquage)

**Variantes spÃ©cialisÃ©es** :

```mermaid
graph TD
    A[DFS Variants] --> B[DFS Standard]
    A --> C[DFS LimitÃ©e]
    A --> D[Iterative Deepening]
    
    B --> B1["Risque: cycles infinis<br/>Usage: arbres, backtracking"]
    C --> C1["Limite de profondeur<br/>Usage: temps limitÃ©"]
    D --> D1["DFS avec limites croissantes<br/>Usage: optimal + mÃ©moire O(bd)"]
```

**ProblÃ¨mes frÃ©quents et solutions** :

```python
# ProblÃ¨me: Stack Overflow avec rÃ©cursion profonde
# Solution: ImplÃ©mentation itÃ©rative
def dfs_iterative(problem):
    stack = [initial_node]
    visited = set()
    
    while stack:
        node = stack.pop()
        if node.state in visited:
            continue
        visited.add(node.state)
        
        for child in expand(node):
            if child.state not in visited:
                stack.append(child)
```

---

## â¬‡ï¸ Algorithme 2 : Le "tunnel" (Recherche en profondeur - DFS)

### ğŸ  L'analogie simple : Chercher ses clÃ©s comme un explorateur de grottes

**Revenons Ã  nos clÃ©s perdues, mais avec une stratÃ©gie diffÃ©rente :**

```mermaid
graph TD
    subgraph "ğŸ  Ma maison - StratÃ©gie tunnel"
        A[ğŸšª Je commence<br/>Ã  l'entrÃ©e] 
        A --> B[ğŸ›‹ï¸ Salon]
        B --> E[ğŸ“º DerriÃ¨re TV]
        E --> I[ğŸ“± Sous tÃ©lÃ©commande]
        I --> J[ğŸ”Œ DerriÃ¨re prises]
        J --> K[ğŸ§½ Dans coussins]
        K --> L[ğŸ’¡ Sous lampe]
        L --> M{ğŸ”‘ TrouvÃ©es !}
    end
    
    style A fill:#e3f2fd
    style M fill:#c8e6c9
```

**La stratÃ©gie "tunnel" :**
1. ğŸ¯ J'entre dans le salon
2. ğŸ¯ Je fouille **complÃ¨tement** derriÃ¨re la TV
3. ğŸ¯ Si pas trouvÃ©, je fouille **complÃ¨tement** la tÃ©lÃ©commande  
4. ğŸ¯ Si pas trouvÃ©, je fouille **complÃ¨tement** derriÃ¨re les prises
5. ğŸ¯ Je continue jusqu'au bout de cette "branche", puis je reviens en arriÃ¨re

### ğŸ¤” Pourquoi cette mÃ©thode est intelligente ?

**âœ… Avantages :**
- **ğŸ§  MÃ©moire Ã©conome** : Je n'ai besoin de me rappeler que du "chemin" que je suis en train de suivre
- **âš¡ Peut Ãªtre trÃ¨s rapide** : Si mes clÃ©s sont cachÃ©es profondÃ©ment quelque part, je peux tomber dessus rapidement !
- **ğŸ”„ Simple Ã  programmer** : TrÃ¨s naturel avec la rÃ©cursion

**âŒ InconvÃ©nients :**  
- **ğŸŒ€ Risque de boucle** : Je peux tourner en rond si je ne fais pas attention !
- **âŒ Pas forcÃ©ment optimal** : Je peux trouver mes clÃ©s au 3Ã¨me Ã©tage alors qu'elles Ã©taient dans l'entrÃ©e...
- **ğŸ² DÃ©pend de la chance** : Si je commence par la mauvaise direction, Ã§a peut prendre trÃ¨s longtemps

### ğŸ” Comment Ã§a marche concrÃ¨tement ?

```mermaid
flowchart TD
    subgraph "ğŸ¯ StratÃ©gie tunnel"
        A[ğŸ“ Je suis quelque part] --> B{ğŸ”‘ ClÃ©s ici ?}
        B -->|âœ… Oui| C[ğŸ‰ TerminÃ© !]
        B -->|âŒ Non| D{ğŸšª PiÃ¨ce voisine ?}
        D -->|âœ… Oui| E[â¡ï¸ J'y vais et je continue]
        D -->|âŒ Non| F[â¬…ï¸ Je reviens en arriÃ¨re]
        E --> A
        F --> A
    end
```

**Exemple concret :**
- **Ã‰tape 1** : EntrÃ©e â†’ Salon (je choisis le salon)
- **Ã‰tape 2** : Salon â†’ DerriÃ¨re TV (je m'enfonce)
- **Ã‰tape 3** : DerriÃ¨re TV â†’ Sous tÃ©lÃ©commande (je continue Ã  m'enfoncer)
- **Ã‰tape 4** : Sous tÃ©lÃ©commande â†’ Pas trouvÃ©, je reviens
- **Ã‰tape 5** : DerriÃ¨re TV â†’ DerriÃ¨re prises (j'essaie autre chose au mÃªme niveau)
- **Etc...**

### ğŸ® Pourquoi on appelle Ã§a "Depth-First Search" (DFS) ?

- **"Depth"** = Profondeur â†’ On va le plus **profond** possible
- **"First"** = D'abord â†’ Avant d'essayer autre chose

C'est comme un spÃ©lÃ©ologue qui explore une grotte jusqu'au bout !

### ğŸ†š DFS vs BFS : Quelle diffÃ©rence ?

```mermaid
graph LR
    subgraph "ğŸŒŠ BFS (Vague)"
        A1[ğŸ  EntrÃ©e] --> B1[Toutes piÃ¨ces RDC]
        B1 --> C1[Toutes piÃ¨ces 1er]
        C1 --> D1[Toutes piÃ¨ces 2Ã¨me]
    end
    
    subgraph "â¬‡ï¸ DFS (Tunnel)"  
        A2[ğŸ  EntrÃ©e] --> B2[Salon]
        B2 --> C2[DerriÃ¨re TV]
        C2 --> D2[Sous tÃ©lÃ©commande]
        D2 --> E2[Etc... jusqu'au bout]
    end
```

**Analogie simple :**
- **BFS** = comme remplir une piscine ğŸŠâ€â™‚ï¸ (l'eau monte niveau par niveau)
- **DFS** = comme creuser un puits â›ï¸ (on va profond en premier)

---

### ğŸ’» Version technique pour les curieux

### 2. Recherche en profondeur (DFS) - Analyse approfondie

```mermaid
flowchart TD
    A[A* Algorithm] --> B[Fonction d'Ã©valuation]
    A --> C[PropriÃ©tÃ©s clÃ©s]
    A --> D[Structures de donnÃ©es]
    
    B --> B1["f = g + h<br/>g: coÃ»t rÃ©el<br/>h: heuristique"]
    C --> C1["AdmissibilitÃ©<br/>Consistance<br/>OptimalitÃ©"]
    D --> D1["Open-set: Heap<br/>Closed-set: Set<br/>Came-from: Dict"]
    
    style A fill:#e8f5e8
    style C1 fill:#fff8e1
```

**Principe dÃ©taillÃ©** : Recherche informÃ©e utilisant une heuristique admissible pour guider l'exploration vers le but.

**Avantages spÃ©cifiques** :

- **Optimale garantie** : Avec heuristique admissible, trouve toujours le chemin optimal
- **EfficacitÃ© dirigÃ©e** : Guide l'exploration vers le but, Ã©vite les dÃ©tours inutiles
- **Flexible** : S'adapte Ã  diffÃ©rents domaines via l'heuristique
- **ThÃ©oriquement optimal** : DÃ©veloppe le minimum de nÅ“uds nÃ©cessaires (optimalitÃ© relative)

**InconvÃ©nients et limitations** :

- **DÃ©pendance heuristique** : Performance directement liÃ©e Ã  la qualitÃ© de h(n)
- **MÃ©moire Ã©levÃ©e** : Doit maintenir tous les nÅ“uds dans l'open-set
- **CoÃ»t computationnel** : Calcul d'heuristique + gestion de structures complexes
- **Pas de garantie temporelle** : Peut Ãªtre trÃ¨s lent avec heuristiques pauvres

**Analyse de complexitÃ© dÃ©taillÃ©e** :

```mermaid
graph TD
    A[ComplexitÃ© A*] --> B[Temps]
    A --> C[Espace]
    
    B --> B1["Optimal: O(b exposant d)<br/>Moyenne: O(b exposant h x d)<br/>h = facteur d'erreur"]
    C --> C1["Open-set: O(b exposant d)<br/>Closed-set: O(b exposant d)<br/>Total: O(b exposant d)"]
```

**Cas d'usage optimaux** :

- **Navigation GPS** : Avec heuristique distance euclidienne
- **Jeux vidÃ©o** : Pathfinding NPCs avec obstacles
- **Robotique** : Planification de mouvement avec contraintes
- **RÃ©seaux** : Routage optimal avec mÃ©triques de coÃ»t

**ProblÃ¨mes courants et solutions** :

```python
# ProblÃ¨me: Tie-breaking sous-optimal
# Solution: PrÃ©fÃ©rer nÅ“uds avec g plus Ã©levÃ©
def tie_breaking_heuristic(node, goal):
    h = manhattan_distance(node, goal)
    # LÃ©gÃ¨re prÃ©fÃ©rence pour chemins plus longs
    return h + 0.001 * node.g

# ProblÃ¨me: Reopen de nÅ“uds fermÃ©s
# Solution: VÃ©rifier si nouveau chemin est meilleur
if neighbor in closed_set:
    if tentative_g < g_score[neighbor]:
        closed_set.remove(neighbor)
        # RÃ©insÃ©rer dans open_set avec nouveau score
```

### 4. Recherche locale (Hill Climbing) - Analyse approfondie

```mermaid
flowchart TD
    A[Hill Climbing] --> B[Types]
    A --> C[ProblÃ¨mes]
    A --> D[Solutions]
    
    B --> B1[Simple<br/>Stochastic<br/>First-choice<br/>Random restart]
    C --> C1[Local maxima<br/>Plateaux<br/>Ridges]
    D --> D1[Simulated Annealing<br/>Tabu Search<br/>Multiple restarts]
    
    style A fill:#fff3e0
    style C1 fill:#ffebee
```

**Principe dÃ©taillÃ©** : Partir d'une solution et l'amÃ©liorer itÃ©rativement en choisissant toujours le meilleur voisin.

**Avantages spÃ©cifiques** :

- **SimplicitÃ© extrÃªme** : Algorithme intuitif et facile Ã  implÃ©menter
- **MÃ©moire constante** : Ne garde que la solution courante
- **RapiditÃ©** : Convergence rapide vers optimum local
- **Polyvalence** : Applicable Ã  tout problÃ¨me avec voisinage dÃ©fini

**InconvÃ©nients et limitations** :

- **Optima locaux** : Se bloque sur solutions sous-optimales
- **Pas de backtracking** : Ne peut pas revenir en arriÃ¨re
- **DÃ©pendance Ã  l'initial** : RÃ©sultat trÃ¨s variable selon point de dÃ©part
- **Plateaux** : Progression impossible sur zones plates

**Types et leurs caractÃ©ristiques** :

```python
# Simple Hill Climbing - dÃ©terministe
def simple_hill_climbing(problem):
    current = random_state()
    while True:
        neighbor = best_neighbor(current)
        if value(neighbor) <= value(current):
            return current
        current = neighbor

# Stochastic - choix probabiliste parmi amÃ©liorations
def stochastic_hill_climbing(problem):
    current = random_state()
    while True:
        neighbors = get_improving_neighbors(current)
        if not neighbors:
            return current
        current = random.choice(neighbors)
```

**StratÃ©gies d'amÃ©lioration** :

- **Random Restart** : Multiples exÃ©cutions depuis points diffÃ©rents
- **Tabu Search** : Ã‰viter de revisiter rÃ©centes solutions
- **Variable Neighborhood** : Changer de voisinage quand bloquÃ©

### 5. Recuit SimulÃ© (Simulated Annealing) - Analyse approfondie

```mermaid
flowchart TD
    A[Simulated Annealing] --> B[Inspiration physique]
    A --> C[ParamÃ¨tres critiques]
    A --> D[Schedules tempÃ©rature]
    
    B --> B1["Refroidissement mÃ©taux<br/>Ã‰nergie â†’ Ordre cristallin"]
    C --> C1["Tâ‚€: TempÃ©rature initiale<br/>alpha: Taux refroidissement<br/>Voisinage: Fonction transition"]
    D --> D1["GÃ©omÃ©trique: T x alpha<br/>Logarithmique: T/(1+alpha x t)<br/>Adaptatif: BasÃ© performance"]
    
    style A fill:#e3f2fd
    style C1 fill:#fff8e1
```

**Principe dÃ©taillÃ©** : Accepter des dÃ©gradations temporaires avec probabilitÃ© dÃ©croissante pour Ã©chapper aux optima locaux.

**Avantages spÃ©cifiques** :

- **Ã‰chappement garanti** : Peut sortir des optima locaux contrairement Ã  Hill Climbing
- **Convergence thÃ©orique** : Avec schedule appropriÃ©, converge vers optimum global
- **SimplicitÃ© relative** : Plus simple que les mÃ©ta-heuristiques populationnelles
- **ContrÃ´le fin** : ParamÃ¨tres permettent ajustement prÃ©cis du comportement

**InconvÃ©nients et limitations** :

- **RÃ©glage dÃ©licat** : ParamÃ¨tres Tâ‚€ et Î± critiques pour performance
- **Pas de garantie temps** : Convergence peut Ãªtre trÃ¨s lente
- **Voisinage crucial** : QualitÃ© dÃ©pend fortement de la fonction de transition
- **Stochastique** : RÃ©sultats variables entre exÃ©cutions

**RÃ©glage pratique des paramÃ¨tres** :

```python
# Estimation Tâ‚€: accepter ~80% des mauvais mouvements initialement
def estimate_initial_temperature(problem, sample_size=100):
    current = random_solution()
    deltas = []
    
    for _ in range(sample_size):
        neighbor = random_neighbor(current)
        delta = cost(neighbor) - cost(current)
        if delta > 0:
            deltas.append(delta)
        current = neighbor
    
    # Tâ‚€ tel que exp(-avg_delta/Tâ‚€) = 0.8
    avg_delta = sum(deltas) / len(deltas)
    return -avg_delta / math.log(0.8)
```

**Schedules de refroidissement avancÃ©s** :

```mermaid
graph LR
    A[Cooling Schedules] --> B[GÃ©omÃ©trique]
    A --> C[Logarithmique]  
    A --> D[Adaptatif]
    
    B --> B1["T = Tâ‚€ x alpha exposant t<br/>alpha âˆˆ [0.8, 0.99]"]
    C --> C1["T = Tâ‚€ / (1 + alpha x t)<br/>Plus lent"]
    D --> D1["Ajuste selon<br/>taux acceptation"]
```

### 6. Algorithmes GÃ©nÃ©tiques - Analyse approfondie

```mermaid
flowchart TD
    A[Genetic Algorithms] --> B[Composants]
    A --> C[OpÃ©rateurs]
    A --> D[ParamÃ¨tres]
    
    B --> B1[Population<br/>Fitness<br/>SÃ©lection<br/>Reproduction]
    C --> C1[Crossover<br/>Mutation<br/>SÃ©lection survivants]
    D --> D1[Taille population<br/>Taux crossover<br/>Taux mutation<br/>GÃ©nÃ©rations]
    
    style A fill:#f1f8e9
    style D1 fill:#fff3e0
```

**Principe dÃ©taillÃ©** : Ã‰volution d'une population de solutions par sÃ©lection, croisement et mutation.

**Avantages spÃ©cifiques** :

- **Exploration globale** : Population diverse Ã©vite les optima locaux
- **ParallÃ©lisme naturel** : Ã‰valuation fitness et opÃ©rateurs parallÃ©lisables
- **Pas de gradient requis** : Fonctionne sur espaces discrets et discontinus
- **Robustesse** : RÃ©sistant au bruit et aux espaces multimodaux

**InconvÃ©nients et limitations** :

- **Nombreux paramÃ¨tres** : RÃ©glage dÃ©licat de tous les hyperparamÃ¨tres
- **Convergence lente** : Peut nÃ©cessiter many gÃ©nÃ©rations
- **Pas de garantie** : Aucune garantie d'optimalitÃ© ou mÃªme d'amÃ©lioration
- **ReprÃ©sentation critique** : Encodage doit Ãªtre adaptÃ© au problÃ¨me

**OpÃ©rateurs spÃ©cialisÃ©s par type de problÃ¨me** :

```mermaid
graph TD
    A[ProblÃ¨me] --> B[TSP - Permutations]
    A --> C[Optimisation continue]
    A --> D[ProblÃ¨mes binaires]
    
    B --> B1[PMX, OX, CX<br/>Inversion, Swap]
    C --> C1["BLX-alpha, SBX<br/>Gaussian mutation"]
    D --> D1[Uniform, N-point<br/>Bit flip]
```

**RÃ©glage des paramÃ¨tres** :

```python
# RÃ¨gles empiriques courantes
population_size = min(100, 4 * problem_dimension)
crossover_rate = 0.7  # 70% des individus se reproduisent
mutation_rate = 1.0 / chromosome_length  # ~1 bit par individu
selection_pressure = 2.0  # dans tournament selection

# Adaptation dynamique
def adaptive_mutation_rate(generation, max_generations):
    # Forte mutation au dÃ©but, faible Ã  la fin
    return 0.1 * (1 - generation / max_generations) + 0.01
```

**Algorithmes hybrides (Memetic)** :

```python
# Combinaison GA + recherche locale
def memetic_algorithm(problem):
    population = initialize_population()
    
    for generation in range(max_generations):
        # Phase gÃ©nÃ©tique classique
        offspring = genetic_operations(population)
        
        # Phase recherche locale sur les meilleurs
        for individual in best_n(offspring, local_search_ratio):
            individual = local_search(individual)  # 2-opt, hill climbing, etc.
        
        population = select_survivors(population + offspring)
    
    return best_individual(population)
```

**Pseudocode** :
```python
from collections import deque

def bfs(probleme):
    """
    Recherche en largeur d'abord
    
    Args:
        probleme: Objet problÃ¨me avec mÃ©thodes:
            - etat_initial: Ã©tat de dÃ©part
            - est_but(etat): test si Ã©tat est solution
            - actions(etat): actions possibles depuis l'Ã©tat
            - resultat(etat, action): nouvel Ã©tat aprÃ¨s action
    
    Returns:
        Chemin vers la solution ou None si pas de solution
    """
    noeud_initial = Noeud(probleme.etat_initial)
    
    if probleme.est_but(noeud_initial.etat):
        return noeud_initial.chemin()
    
    frontiere = deque([noeud_initial])  # File FIFO
    explore = set()
    
    while frontiere:
        noeud = frontiere.popleft()
        explore.add(noeud.etat)
        
        for action in probleme.actions(noeud.etat):
            enfant = noeud.enfant(probleme, action)
            
            if enfant.etat not in explore and enfant not in frontiere:
                if probleme.est_but(enfant.etat):
                    return enfant.chemin()
                frontiere.append(enfant)
    
    return None  # Pas de solution trouvÃ©e

class Noeud:
    """NÅ“ud dans l'arbre de recherche"""
    def __init__(self, etat, parent=None, action=None, cout_chemin=0):
        self.etat = etat
        self.parent = parent
        self.action = action
        self.cout_chemin = cout_chemin
        self.profondeur = 0 if parent is None else parent.profondeur + 1
    
    def enfant(self, probleme, action):
        """CrÃ©e un nÅ“ud enfant en appliquant une action"""
        nouvel_etat = probleme.resultat(self.etat, action)
        cout = self.cout_chemin + probleme.cout_action(self.etat, action)
        return Noeud(nouvel_etat, self, action, cout)
    
    def chemin(self):
        """Retourne le chemin depuis la racine"""
        noeud, chemin = self, []
        while noeud:
            chemin.append(noeud.action)
            noeud = noeud.parent
        return list(reversed(chemin))[1:]  # Exclut None initial

# Exemple d'utilisation : Puzzle 8
class Puzzle8:
    def __init__(self, etat_initial, etat_but):
        self.etat_initial = tuple(etat_initial)
        self.etat_but = tuple(etat_but)
    
    def est_but(self, etat):
        return etat == self.etat_but
    
    def actions(self, etat):
        """Actions possibles : dÃ©placer la case vide"""
        actions = []
        pos_vide = etat.index(0)
        ligne, col = pos_vide // 3, pos_vide % 3
        
        if ligne > 0: actions.append('HAUT')
        if ligne < 2: actions.append('BAS')
        if col > 0: actions.append('GAUCHE')
        if col < 2: actions.append('DROITE')
        
        return actions
    
    def resultat(self, etat, action):
        """Applique l'action et retourne le nouvel Ã©tat"""
        etat = list(etat)
        pos_vide = etat.index(0)
        ligne, col = pos_vide // 3, pos_vide % 3
        
        if action == 'HAUT':
            nouvelle_pos = (ligne - 1) * 3 + col
        elif action == 'BAS':
            nouvelle_pos = (ligne + 1) * 3 + col
        elif action == 'GAUCHE':
            nouvelle_pos = ligne * 3 + (col - 1)
        elif action == 'DROITE':
            nouvelle_pos = ligne * 3 + (col + 1)
        
        # Ã‰change case vide avec case adjacente
        etat[pos_vide], etat[nouvelle_pos] = etat[nouvelle_pos], etat[pos_vide]
        return tuple(etat)
    
    def cout_action(self, etat, action):
        return 1  # CoÃ»t uniforme

# Test sur un puzzle simple
puzzle = Puzzle8(
    etat_initial=[1, 2, 3, 4, 0, 5, 6, 7, 8],
    etat_but=[1, 2, 3, 4, 5, 0, 6, 7, 8]
)

solution = bfs(puzzle)
print("Solution trouvÃ©e:", solution)
# Sortie: ['DROITE', 'BAS']
```

### Diagramme et intuition BFS vs DFS

```mermaid
flowchart LR
    subgraph BFS[Recherche en largeur - BFS]
        A1[Start] --> B1[Niveau 1]
        B1 --> C1[Niveau 2]
        C1 --> D1[Goal]
    end
    subgraph DFS[Recherche en profondeur - DFS]
        A2[Start] --> B2[Branche A]
        B2 --> C2[Branche A profonde]
        C2 --> D2[Goal possible profond]
    end
    classDef startend fill:#eef,stroke:#333;
    class A1,A2,D1,D2 startend;
```

Explication :
- BFS explore par couches : utile pour trouver le chemin le plus court en nombre d'actions. MÃ©moire Ã©levÃ©e.
- DFS plonge profond dans une branche : faible mÃ©moire mais risque d'entrer dans des boucles ou de manquer une solution peu profonde.

Cas pratiques et astuces :
- Utiliser BFS quand la profondeur de la solution est faible et le facteur de branchement raisonnable.
- Utiliser DFS (avec visite) ou DFS limitÃ©e quand la profondeur est Ã©levÃ©e mais la mÃ©moire est contrainte.
- Pour espaces infinis ou avec cycles, toujours garder un ensemble d'Ã©tats visitÃ©s ou appliquer une limite de profondeur.

### 2. Recherche en profondeur (DFS)

**Principe** : Explorer une branche complÃ¨tement avant de revenir en arriÃ¨re.

**Avantages** :
- MÃ©moire linÃ©aire O(bm) oÃ¹ m = profondeur maximale
- Peut trouver des solutions rapidement si elles sont profondes

**InconvÃ©nients** :
- Non optimale
- Peut boucler infiniment
- Mauvaise performance si la solution est proche de la racine

### 3. Recherche en profondeur limitÃ©e

Variante de DFS avec une limite de profondeur pour Ã©viter les boucles infinies.

## Algorithmes de recherche informÃ©e (heuristique)

### 1. Recherche gourmande (Greedy)

Utilise une fonction heuristique h(n) qui estime le coÃ»t du nÅ“ud n vers le but.

**Avantages** :
- Rapide et Ã©conome en mÃ©moire
- Efficace quand l'heuristique est bonne

**InconvÃ©nients** :
- Non optimale
- IncomplÃ¨te (peut se coincer dans des impasses)

---

## ğŸ§­ Algorithme 3 : Le "GPS intelligent" (Algorithme A*)

### ğŸ  L'analogie simple : Chercher ses clÃ©s avec des indices

**Revenons encore Ã  nos clÃ©s perdues, mais cette fois avec une approche plus maligne :**

Imaginez que vous avez un **dÃ©tecteur de clÃ©s** qui bipte plus fort quand vous vous rapprochez ! ğŸ”Š

```mermaid
graph TD
    subgraph "ğŸ  Ma maison avec dÃ©tecteur"
        A[ğŸšª EntrÃ©e<br/>ğŸ”Š Bip faible] 
        A --> B[ğŸ›‹ï¸ Salon<br/>ğŸ”ŠğŸ”Š Bip moyen]
        A --> C[ğŸ½ï¸ Cuisine<br/>ğŸ”Š Bip faible]  
        B --> D[ğŸ“º DerriÃ¨re TV<br/>ğŸ”ŠğŸ”ŠğŸ”Š Bip fort]
        D --> E[ğŸ”‘ MES CLÃ‰S !<br/>ğŸ”ŠğŸ”ŠğŸ”ŠğŸ”Š TRÃˆS FORT]
    end
    
    style A fill:#e3f2fd
    style E fill:#c8e6c9
```

**La stratÃ©gie "GPS intelligent" :**
1. ğŸ¯ Je commence comme BFS, mais...
2. ğŸ§­ **Au lieu d'explorer au hasard, je privilÃ©gie les directions oÃ¹ le dÃ©tecteur bipe le plus fort !**
3. ğŸ¯ Je combine : "distance parcourue" + "signal du dÃ©tecteur"
4. âœ… J'arrive plus vite au bon endroit !

### ğŸ¤” Pourquoi cette mÃ©thode est gÃ©niale ?

**âœ… Avantages :**
- **ğŸ“ Optimal comme BFS** : Trouve toujours le chemin le plus court !
- **ğŸš€ Plus rapide que BFS** : Ã‰vite d'explorer dans les mauvaises directions
- **ğŸ§­ Utilise l'intelligence** : Exploite les informations disponibles sur le problÃ¨me
- **âš–ï¸ Ã‰quilibre parfait** : Combine systematic (BFS) + guidage intelligent

**âŒ InconvÃ©nients :**
- **ğŸ§  Plus complexe** : Il faut programmer le "dÃ©tecteur" (heuristique)
- **ğŸ§® Plus de calculs** : Doit Ã©valuer chaque position
- **ğŸ¯ DÃ©pend de la qualitÃ© du dÃ©tecteur** : Si le dÃ©tecteur ment, Ã§a marche mal !

### ğŸ” Comment Ã§a marche concrÃ¨tement ?

```mermaid
flowchart TD
    subgraph "ğŸ¯ A* en action"
        A[ğŸ“ Je suis quelque part] --> B["ğŸ§® Je calcule pour chaque voisin :<br/>Distance parcourue + Signal dÃ©tecteur"]
        B --> C[ğŸ“Š Je classe tous les voisins]
        C --> D[ğŸ‘‘ Je choisis le MEILLEUR voisin]
        D --> E{ğŸ”‘ ClÃ©s trouvÃ©es ?}
        E -->|âœ… Oui| F[ğŸ‰ TerminÃ© !]
        E -->|âŒ Non| A
    end
```

**Exemple concret avec des chiffres :**

| Endroit | Distance parcourue | Signal dÃ©tecteur | **TOTAL** | DÃ©cision |
|---------|-------------------|------------------|-----------|----------|
| ğŸ½ï¸ Cuisine | 3 Ã©tapes | 8 (bip faible) | **11** | âŒ |
| ğŸ›‹ï¸ Salon | 2 Ã©tapes | 4 (bip moyen) | **6** | âœ… **CHOISI !** |
| ğŸš¿ Salle de bain | 2 Ã©tapes | 9 (bip faible) | **11** | âŒ |

ğŸ¯ **A* choisit toujours le voisin avec le PLUS PETIT total !**

### ğŸ® Pourquoi on appelle Ã§a "A-star" (A*) ?

- **A** = Le nom de l'algorithme (comme dans "Algorithm A")
- **\*** = "Star" = â­ = **OPTIMAL** = Le meilleur possible !

C'est l'algorithme "Ã©toile" parce qu'il combine le meilleur des deux mondes !

### ğŸ†š A* vs BFS vs DFS : La comparaison ultime

```mermaid
graph TD
    subgraph "ğŸŒŠ BFS : SystÃ©matique mais aveugle"
        A1[Explore TOUT niveau par niveau<br/>âœ… Optimal âŒ Peut Ãªtre lent]
    end
    
    subgraph "â¬‡ï¸ DFS : Rapide mais risquÃ©"  
        A2[Va profond directement<br/>âœ… Ã‰conome âŒ Pas optimal]
    end
    
    subgraph "ğŸ§­ A* : Le meilleur des deux !"
        A3[SystÃ©matique + Guidage intelligent<br/>âœ… Optimal âœ… Rapide âœ… Malin]
    end
    
    style A3 fill:#c8e6c9
```

**Analogie simple :**
- **BFS** = Explorer mÃ©thodiquement mais sans rÃ©flÃ©chir ğŸ¤–
- **DFS** = Foncer au hasard en espÃ©rant avoir de la chance ğŸ²  
- **A*** = Utiliser sa tÃªte ET Ãªtre mÃ©thodique ğŸ§ â­

### ğŸ”® Le secret de A* : L'heuristique

**L'heuristique, c'est votre "dÃ©tecteur de clÃ©s" !**

Quelques exemples de "dÃ©tecteurs" selon le problÃ¨me :

#### ğŸ—ºï¸ Pour la navigation GPS :
- **DÃ©tecteur** : Distance Ã  vol d'oiseau vers la destination
- **Logique** : Plus je suis proche Ã  vol d'oiseau, plus je suis probablement proche par la route

#### ğŸ§© Pour un puzzle :
- **DÃ©tecteur** : Nombre de piÃ¨ces mal placÃ©es
- **Logique** : Moins il y a de piÃ¨ces mal placÃ©es, plus je suis proche de la solution

#### ğŸ® Pour un jeu vidÃ©o :
- **DÃ©tecteur** : Distance Manhattan vers le trÃ©sor  
- **Logique** : Plus je suis proche du trÃ©sor, mieux c'est

### ğŸ¯ La rÃ¨gle d'or de A*

**Pour que A* soit optimal, le dÃ©tecteur ne doit JAMAIS surestimer !**

ğŸš« **Mauvais dÃ©tecteur** : "Il reste 2 km" alors qu'il en reste vraiment 5 km
âœ… **Bon dÃ©tecteur** : "Il reste 5 km" alors qu'il en reste vraiment 3 km

**Pourquoi ?** Si le dÃ©tecteur sous-estime, A* peut ignorer le vrai chemin optimal !

---

### ğŸ’» Version technique pour les curieux

### 2. Algorithme A*

**Fonction d'Ã©valuation** : f(n) = g(n) + h(n)
- g(n) : coÃ»t rÃ©el du chemin depuis le dÃ©but
- h(n) : heuristique (estimation du coÃ»t vers le but)

**Conditions pour l'optimalitÃ©** :
- **Heuristique admissible** : h(n) â‰¤ h*(n) oÃ¹ h*(n) est le coÃ»t rÃ©el optimal
- **Heuristique consistante** : h(n) â‰¤ c(n,a,n') + h(n') pour toute action a

**Exemple d'heuristique** : Distance euclidienne pour la navigation
```
h(n) = racine[(x_but - x_n)Â² + (y_but - y_n)Â²]
```

**ImplÃ©mentation complÃ¨te d'A*** :

```python
import heapq
import math

class AStar:
    def __init__(self, grille, debut, fin):
        self.grille = grille
        self.debut = debut
        self.fin = fin
        self.lignes = len(grille)
        self.cols = len(grille[0])
    
    def heuristique(self, noeud):
        """Distance euclidienne vers le but"""
        x1, y1 = noeud
        x2, y2 = self.fin
        return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)
    
    def voisins(self, noeud):
        """Retourne les voisins valides d'un nÅ“ud"""
        x, y = noeud
        voisins = []
        
        # 8 directions possibles (incluant diagonales)
        directions = [(-1,-1), (-1,0), (-1,1), (0,-1), (0,1), (1,-1), (1,0), (1,1)]
        
        for dx, dy in directions:
            nx, ny = x + dx, y + dy
            
            # VÃ©rifier les limites
            if 0 <= nx < self.lignes and 0 <= ny < self.cols:
                # VÃ©rifier si la case n'est pas un obstacle
                if self.grille[nx][ny] != 1:  # 0 = libre, 1 = obstacle
                    voisins.append((nx, ny))
        
        return voisins
    
    def cout_mouvement(self, actuel, voisin):
        """CoÃ»t de dÃ©placement entre deux cases adjacentes"""
        x1, y1 = actuel
        x2, y2 = voisin
        
        # CoÃ»t diagonal = racine(2), coÃ»t orthogonal = 1
        if abs(x2 - x1) == 1 and abs(y2 - y1) == 1:
            return math.sqrt(2)
        else:
            return 1
    
    def rechercher(self):
        """Algorithme A* principal"""
        # File de prioritÃ© : (f_score, noeud)
        frontiere = [(0, self.debut)]
        heapq.heapify(frontiere)
        
        # Dictionnaires pour stocker les scores et chemins
        g_score = {self.debut: 0}  # CoÃ»t rÃ©el depuis le dÃ©but
        f_score = {self.debut: self.heuristique(self.debut)}  # f = g + h
        vient_de = {}  # Pour reconstruire le chemin
        explore = set()
        
        while frontiere:
            # Prendre le nÅ“ud avec le plus petit f_score
            _, actuel = heapq.heappop(frontiere)
            
            if actuel in explore:
                continue
            
            explore.add(actuel)
            
            # But atteint ?
            if actuel == self.fin:
                return self.reconstruire_chemin(vient_de, actuel)
            
            # Explorer les voisins
            for voisin in self.voisins(actuel):
                if voisin in explore:
                    continue
                
                # Calcul du nouveau g_score
                cout_tentative = g_score[actuel] + self.cout_mouvement(actuel, voisin)
                
                # Si on a trouvÃ© un meilleur chemin vers ce voisin
                if voisin not in g_score or cout_tentative < g_score[voisin]:
                    vient_de[voisin] = actuel
                    g_score[voisin] = cout_tentative
                    f_score[voisin] = cout_tentative + self.heuristique(voisin)
                    
                    # Ajouter Ã  la frontiÃ¨re
                    heapq.heappush(frontiere, (f_score[voisin], voisin))
        
        return None  # Pas de chemin trouvÃ©
    
    def reconstruire_chemin(self, vient_de, actuel):
        """Reconstruit le chemin depuis le dÃ©but"""
        chemin = [actuel]
        while actuel in vient_de:
            actuel = vient_de[actuel]
            chemin.append(actuel)
        return list(reversed(chemin))

# Exemple d'utilisation
grille = [
    [0, 0, 0, 1, 0],
    [0, 1, 0, 1, 0],
    [0, 1, 0, 0, 0],
    [0, 0, 0, 1, 0],
    [0, 0, 0, 0, 0]
]

astar = AStar(grille, debut=(0, 0), fin=(4, 4))
chemin = astar.rechercher()

if chemin:
    print("Chemin optimal trouvÃ©:")
    for i, (x, y) in enumerate(chemin):
        print(f"Ã‰tape {i}: ({x}, {y})")
    print(f"Longueur totale: {len(chemin) - 1} Ã©tapes")
else:
    print("Aucun chemin trouvÃ©")

# Sortie exemple:
# Chemin optimal trouvÃ©:
# Ã‰tape 0: (0, 0)
# Ã‰tape 1: (1, 0)
# Ã‰tape 2: (2, 0)
# Ã‰tape 3: (3, 0)
# Ã‰tape 4: (3, 1)
# Ã‰tape 5: (4, 2)
# Ã‰tape 6: (4, 3)
# Ã‰tape 7: (4, 4)
```

### Diagramme de flux A* (haute-niveau)

```mermaid
flowchart TB
    A[DÃ©but] --> B{FrontiÃ¨re non vide}
    B -->|oui| C[Extraire nÅ“ud min f]
    C --> D{Noeud = but ?}
    D -->|oui| E[Reconstruire chemin]
    D -->|non| F[Explorer voisins]
    F --> G{Meilleur g?}
    G -->|oui| H[Mettre Ã  jour g,f et ajouter Ã  frontiÃ¨re]
    G -->|non| I[Ignorer]
    H --> B
    I --> B
    B -->|non| J[Ã‰chec - pas de chemin]
```

![Chemin A* sur grille](/lms/astar-grid.svg)

### AdmissibilitÃ© vs Consistance â€” intuition et preuve courte

- **AdmissibilitÃ©** (h(n) â‰¤ h*(n)) : garantit que l'heuristique ne sous-estime jamais le coÃ»t restant. Ainsi, A* retourne un chemin optimal lorsque le but est extrait de l'open-set la premiÃ¨re fois.
- **Consistance** (h(n) â‰¤ c(n,a,n') + h(n')) : plus forte que l'admissibilitÃ© ; elle implique que f(n) = g(n)+h(n) est non-dÃ©croissante le long de n'importe quel chemin. Quand h est consistante, on n'a pas besoin de rÃ©examiner un nÅ“ud fermÃ©.

Esquisse de preuve : si h est admissible, pour tout n, f(n) = g(n) + h(n) â‰¤ g(n) + h*(n) = coÃ»t d'un chemin optimal passant par n. Donc le chemin optimal global ne peut pas Ãªtre ignorÃ© par A*.

---

## ğŸ”® Le guide des "dÃ©tecteurs magiques" (Heuristiques)

Rappelez-vous : A* utilise un "dÃ©tecteur" pour savoir dans quelle direction aller. En informatique, on appelle Ã§a une **heuristique** !

### ğŸ¯ Pourquoi les heuristiques sont importantes ?

**Imaginez que vous Ãªtes un taxi** ğŸš•

Sans heuristique (dÃ©tecteur), vous Ãªtes comme un taxi **aveugle** :
- Vous devez explorer toutes les rues une par une
- Vous ne savez pas si vous vous rapprochez ou vous Ã©loignez du client
- Ã‡a peut prendre des heures pour une course simple !

Avec une bonne heuristique, vous Ãªtes comme un taxi avec **GPS** :
- Vous savez toujours quelle direction prendre
- Vous Ã©vitez les dÃ©tours inutiles  
- Vous arrivez rapidement Ã  destination !

### ğŸ—ºï¸ Les 3 grandes familles de "dÃ©tecteurs"

```mermaid
graph TD
    subgraph "ğŸ”® Types de dÃ©tecteurs magiques"
        A[ğŸ“ GÃ©omÃ©triques<br/>BasÃ©s sur la distance] 
        B[ğŸ¯ SpÃ©cialisÃ©s<br/>BasÃ©s sur le problÃ¨me]
        C[ğŸ§  Appris<br/>BasÃ©s sur l'expÃ©rience]
    end
    
    A --> A1[ğŸ“ Distance Manhattan<br/>ğŸ—ºï¸ Distance Euclidienne<br/>â™” Distance Chebyshev]
    B --> B1[ğŸ§© Puzzles<br/>ğŸ® Jeux<br/>ğŸ“Š ProblÃ¨mes spÃ©cifiques]
    C --> C1[ğŸ¤– Intelligence artificielle<br/>ğŸ“Š Apprentissage automatique]
```

---

## ğŸ“ Famille 1 : Les dÃ©tecteurs gÃ©omÃ©triques

Ces dÃ©tecteurs utilisent la **gÃ©omÃ©trie simple** pour estimer les distances.

### ğŸ™ï¸ DÃ©tecteur "Manhattan" : Pour les villes en grille

**L'idÃ©e simple :** Ã€ New York, vous ne pouvez pas voler ! Vous devez suivre les rues qui forment une grille.

```mermaid
graph LR
    subgraph "ğŸ—½ Manhattan (New York)"
        A[ğŸ  DÃ©part<br/>5e Avenue & 14e Rue] --> B[ğŸ“ Vous devez aller<br/>2 blocs â†’ Est<br/>3 blocs â†‘ Nord]
        B --> C[ğŸ¯ ArrivÃ©e<br/>7e Avenue & 17e Rue]
    end
```

**Calcul super simple :**
Distance Manhattan = |diffÃ©rence horizontale| + |diffÃ©rence verticale|
= |7-5| + |17-14| = 2 + 3 = **5 blocs**

**Quand l'utiliser ?**
- âœ… Navigation en ville (rues perpendiculaires)
- âœ… Robots qui bougent sur une grille
- âœ… Jeux sur grille (Pac-Man, puzzles)
- âŒ Navigation Ã  vol d'oiseau (avion, bateau)

### ğŸ¦… DÃ©tecteur "Euclidien" : Pour voler comme un oiseau

**L'idÃ©e simple :** Si vous Ã©tiez un oiseau, quelle serait la distance en ligne droite ?

```mermaid
graph LR
    subgraph "ğŸ¦… Vol d'oiseau"
        A[ğŸ  DÃ©part] -.->|ligne droite| C[ğŸ¯ ArrivÃ©e]
        A --> B["ğŸ“ Distance = racine((xâ‚‚-xâ‚)Â² + (yâ‚‚-yâ‚)Â²)"]
    end
```

**Exemple concret :**
- DÃ©part : (0, 0)  
- ArrivÃ©e : (3, 4)
- Distance = racine((3-0)Â² + (4-0)Â²) = racine(9 + 16) = racine(25) = **5 unitÃ©s**

**Quand l'utiliser ?**
- âœ… Navigation aÃ©rienne/maritime  
- âœ… Robotique en espace ouvert
- âœ… Jeux avec mouvement libre (RTS)
- âŒ Environnements avec beaucoup d'obstacles

### â™” DÃ©tecteur "Chebyshev" : Pour les rois d'Ã©checs

**L'idÃ©e simple :** Un roi aux Ã©checs peut bouger dans 8 directions (â†‘â†“â†â†’â†–â†—â†™â†˜). 

```mermaid
graph TD
    subgraph "â™” Mouvement du roi"
        A[ğŸ‘‘ Roi] --> B[â†–]
        A --> C[â†‘] 
        A --> D[â†—]
        A --> E[â†]
        A --> F[â†’]
        A --> G[â†™]
        A --> H[â†“]
        A --> I[â†˜]
    end
```

**Calcul simple :**
Distance Chebyshev = max(|diffÃ©rence horizontale|, |diffÃ©rence verticale|)

**Exemple :** Pour aller de (0,0) Ã  (3,2)
- DiffÃ©rence horizontale : |3-0| = 3
- DiffÃ©rence verticale : |2-0| = 2  
- Distance = max(3, 2) = **3 mouvements**

**Quand l'utiliser ?**
- âœ… Jeux d'Ã©checs (mouvement du roi)
- âœ… Grilles oÃ¹ diagonales = mÃªme coÃ»t qu'orthogonal
- âŒ La plupart des autres cas

---

## ğŸ¯ Famille 2 : Les dÃ©tecteurs spÃ©cialisÃ©s

Ces dÃ©tecteurs sont conÃ§us spÃ©cialement pour certains types de problÃ¨mes.

### ğŸ§© Pour les puzzles : Compter ce qui ne va pas

```mermaid
graph TD
    subgraph "ğŸ§© Puzzle 8"
        A["Ã‰tat actuel<br/>1 2 3<br/>4 _ 6<br/>7 5 8"] 
        B["Ã‰tat dÃ©sirÃ©<br/>1 2 3<br/>4 5 6<br/>7 8 _"]
        C["DÃ©tecteur Hamming<br/>3 piÃ¨ces mal placÃ©es = 3"]
        D["DÃ©tecteur Manhattan<br/>Somme distances = 4"]
    end
```

**DÃ©tecteur Hamming (simple) :**
- Compte juste le nombre de piÃ¨ces mal placÃ©es
- TrÃ¨s rapide mais peu prÃ©cis

**DÃ©tecteur Manhattan (mieux) :**
- Calcule la distance que chaque piÃ¨ce doit parcourir
- Plus lent mais beaucoup plus prÃ©cis

### ğŸ® Pour les jeux : Utiliser les rÃ¨gles du jeu

Chaque jeu a ses propres "astuces" pour estimer qui gagne :

**ğŸ”´ Puissance 4 :** Compter les alignements possibles
**â™Ÿï¸ Ã‰checs :** Valeur des piÃ¨ces + position + contrÃ´le du centre
**ğŸ¯ Tic-tac-toe :** Nombre de lignes/colonnes/diagonales libres

---

## ğŸ§  Famille 3 : Les dÃ©tecteurs appris

**L'idÃ©e rÃ©volutionnaire :** Et si l'ordinateur apprenait tout seul quel est le meilleur dÃ©tecteur ?

```mermaid
flowchart LR
    A[ğŸ® Jouer 1000 parties] --> B[ğŸ§  Analyser les patterns]
    B --> C[ğŸ”® CrÃ©er un dÃ©tecteur intelligent]
    C --> D[ğŸ¯ Utiliser dans A*]
    D --> E[ğŸ“ˆ Performance amÃ©liorÃ©e !]
```

**Exemples modernes :**
- **AlphaGo** : A appris tout seul Ã  jouer au Go
- **GPS modernes** : Apprennent des embouteillages en temps rÃ©el
- **Jeux vidÃ©o** : IA qui s'adapte au style du joueur

---

## âš–ï¸ La rÃ¨gle d'or : L'admissibilitÃ©

**LA rÃ¨gle la plus importante pour A* :**

### ğŸš« DÃ©tecteur qui ment (non-admissible)

```mermaid
graph LR
    A[ğŸ  Position] --> B[ğŸ”® DÃ©tecteur dit : 2 km]
    B --> C[ğŸ¯ RÃ©alitÃ© : 5 km]
    C --> D[âŒ A* peut rater le chemin optimal !]
```

### âœ… DÃ©tecteur honnÃªte (admissible)

```mermaid
graph LR
    A[ğŸ  Position] --> B[ğŸ”® DÃ©tecteur dit : 5 km]  
    B --> C[ğŸ¯ RÃ©alitÃ© : 3 km]
    C --> D[âœ… A* trouve toujours l'optimal !]
```

**La rÃ¨gle simple :** Votre dÃ©tecteur peut sous-estimer, mais ne doit JAMAIS surestimer !

---

## ğŸ› ï¸ Comment crÃ©er son propre dÃ©tecteur ?

### MÃ©thode de la "relaxation" 

**L'astuce gÃ©niale :** Simplifiez votre problÃ¨me !

```mermaid
flowchart TD
    A[ğŸ§© ProblÃ¨me original<br/>avec contraintes compliquÃ©es] --> B[âœ‚ï¸ Supprimer contraintes]
    B --> C[ğŸ§© ProblÃ¨me simplifiÃ©<br/>facile Ã  rÃ©soudre]
    C --> D[ğŸ“ Solution = heuristique !]
```

**Exemple pour le puzzle 8 :**
- **Contrainte originale :** Une seule piÃ¨ce peut bouger Ã  la fois
- **Relaxation :** Toutes les piÃ¨ces peuvent "tÃ©lÃ©porter" instantanÃ©ment  
- **Solution du problÃ¨me relaxÃ© :** Distance Manhattan de chaque piÃ¨ce
- **Heuristique :** Somme de toutes ces distances !

### ğŸ’¡ Conseils pratiques

1. **ğŸ¯ Commencez simple :** Distance euclidienne marche souvent bien
2. **ğŸ“Š Testez et mesurez :** Comparez les performances 
3. **âš–ï¸ VÃ©rifiez l'admissibilitÃ© :** Votre dÃ©tecteur sous-estime-t-il toujours ?
4. **ğŸ”„ ItÃ©rez :** AmÃ©liorez progressivement votre dÃ©tecteur

---

### ğŸ’» Version technique pour les curieux

## Heuristiques : Guide complet et classification

Les heuristiques sont le cÅ“ur de la recherche informÃ©e. Une bonne heuristique peut transformer un problÃ¨me insoluble en problÃ¨me tractable.

### 1. Classification des heuristiques

```mermaid
graph TD
    A[Heuristiques] --> B[Par AdmissibilitÃ©]
    A --> C[Par Source]
    A --> D[Par ComplexitÃ©]
    
    B --> B1[Admissibles]
    B --> B2[Non-admissibles]
    
    C --> C1[GÃ©omÃ©triques]
    C --> C2[Domaine-spÃ©cifique]
    C --> C3[Apprises]
    
    D --> D1["O(1) - Constante"]
    D --> D2["O(n) - LinÃ©aire"]
    D --> D3["O(nÂ²) - Quadratique"]
```

### 2. Heuristiques gÃ©omÃ©triques

#### Distance de Manhattan

```mermaid
graph LR
    subgraph "Grille 4-connexe"
        A[Start] --> B[â€¢ â€¢ â€¢]
        B --> C[â€¢ â€¢ â€¢]
        C --> D[â€¢ â€¢ Goal]
    end
    subgraph "Calcul"
        E["h = abs(xâ‚-xâ‚‚) + abs(yâ‚-yâ‚‚)"]
    end
```

**Formule** : h(n) = |xâ‚ - xâ‚‚| + |yâ‚ - yâ‚‚|

**Avantages** :
- Admissible pour grilles avec mouvements orthogonaux uniquement
- Calcul trÃ¨s rapide O(1)
- Facile Ã  comprendre et implÃ©menter
- Fonctionne bien pour la navigation urbaine (rues en grille)

**InconvÃ©nients** :
- Sous-estime les distances quand les diagonales sont autorisÃ©es
- Non optimal pour espaces continus
- Rigide : ne s'adapte pas aux obstacles

**Usage typique** :
- Navigation sur grille (robots, jeux)
- Planification de chemin urbain
- Puzzles sur grille (8-puzzle, Sokoban)

**Limitations** :
- Ne considÃ¨re pas les obstacles
- InadaptÃ©e aux espaces non-euclidiens
- Perd en prÃ©cision avec terrains variÃ©s

#### Distance Euclidienne

```mermaid
graph LR
    subgraph "Espace continu"
        A[Start] -.->|ligne droite| B[Goal]
    end
    subgraph "Calcul"
        C["h = racine((xâ‚-xâ‚‚)Â² + (yâ‚-yâ‚‚)Â²)"]
    end
```

**Formule** : h(n) = racine[(xâ‚ - xâ‚‚)Â² + (yâ‚ - yâ‚‚)Â²]

**Avantages** :
- Admissible pour mouvements en ligne droite
- Optimale pour espaces continus sans obstacles
- Bonne estimation pour navigation aÃ©rienne/maritime
- Intuitive gÃ©omÃ©triquement

**InconvÃ©nients** :
- Calcul plus coÃ»teux (racine carrÃ©e)
- Sous-estime en prÃ©sence d'obstacles
- InadaptÃ©e aux contraintes de mouvement

**Usage typique** :
- Navigation aÃ©rienne/spatiale
- Robotique mobile en espace ouvert
- GÃ©olocalisation GPS (approximation)

**Optimisations** :
- Utiliser le carrÃ© de la distance pour Ã©viter racine
- PrÃ©-calculer pour grilles fixes
- Approximation par sÃ©ries de Taylor

#### Distance de Chebyshev

```mermaid
graph LR
    subgraph "Grille 8-connexe"
        A[Start] -.->|diagonale| B[Goal]
    end
    subgraph "Calcul"
        C["h = max(abs(xâ‚-xâ‚‚), abs(yâ‚-yâ‚‚))"]
    end
```

**Formule** : h(n) = max(|xâ‚ - xâ‚‚|, |yâ‚ - yâ‚‚|)

**Avantages** :
- Admissible pour grilles avec diagonales au mÃªme coÃ»t
- TrÃ¨s rapide Ã  calculer
- Parfaite pour jeux d'Ã©checs (roi)

**InconvÃ©nients** :
- TrÃ¨s spÃ©cifique aux grilles 8-connexes
- Sous-estime si diagonales coÃ»tent plus cher
- Peu adaptÃ©e aux problÃ¨mes rÃ©els

### 3. Heuristiques domain-spÃ©cifiques

#### 8-Puzzle : Heuristique de Hamming

```mermaid
graph TD
    subgraph "Ã‰tat actuel"
        A[1 2 3<br/>4 0 6<br/>7 5 8]
    end
    subgraph "Ã‰tat but"
        B[1 2 3<br/>4 5 6<br/>7 8 0]
    end
    subgraph "Calcul"
        C["Tuiles mal placÃ©es : 3<br/>h = 3"]
    end
```

**Principe** : Compter le nombre de tuiles mal placÃ©es (sauf case vide)

**Avantages** :
- TrÃ¨s simple Ã  implÃ©menter
- Admissible (chaque tuile nÃ©cessite â‰¥1 mouvement)
- Calcul rapide O(n)

**InconvÃ©nients** :
- Peu informatif (sous-estime beaucoup)
- Ne considÃ¨re pas la distance Ã  parcourir
- Performance mÃ©diocre comparÃ©e Ã  Manhattan

#### 8-Puzzle : Heuristique Manhattan mosaÃ¯que

```mermaid
graph TD
    subgraph "Pour chaque tuile"
        A["Tuile 5 en (1,2)"]
        B["Position but (1,1)"]
        C["Distance = abs(1-1) + abs(2-1) = 1"]
    end
    subgraph "Total"
        D["Somme toutes distances = h"]
    end
```

**Principe** : Somme des distances Manhattan de chaque tuile vers sa position but

**Avantages** :
- Plus informatif que Hamming
- Admissible
- Bon Ã©quilibre prÃ©cision/calcul

**InconvÃ©nients** :
- Ignore les conflits linÃ©aires
- Sous-estime les sÃ©quences de mouvements
- Ne considÃ¨re pas les blocages

#### 8-Puzzle : Linear Conflict

```mermaid
graph TD
    subgraph "Conflit dÃ©tectÃ©"
        A["Ligne: 2 1 3<br/>But: 1 2 3"]
        B["Tuiles 1 et 2 en conflit"]
        C["+2 mouvements additionnels"]
    end
```

**Principe** : Manhattan + 2 Ã— nombre de conflits linÃ©aires

**Avantages** :
- Plus prÃ©cis que Manhattan pure
- Toujours admissible
- Capture les patterns complexes

**InconvÃ©nients** :
- Calcul plus complexe O(nÂ²)
- ImplÃ©mentation dÃ©licate
- SpÃ©cifique aux puzzles coulissants

### 4. Heuristiques pour problÃ¨mes de graphes

#### Voyageur de Commerce (TSP)

```mermaid
graph TD
    A[TSP Heuristiques] --> B[MST Lower Bound]
    A --> C[Nearest Neighbor]
    A --> D[Held-Karp]
    
    B --> B1["Admissible<br/>Rapide O(nÂ²)"]
    C --> C1["Non-admissible<br/>Constructive"]
    D --> D1["TrÃ¨s prÃ©cise<br/>CoÃ»teuse O(nÂ³)"]
```

**MST Lower Bound** :
- **Principe** : CoÃ»t de l'arbre couvrant minimal + 2 arÃªtes minimales
- **Avantages** : Admissible, calcul polynomial
- **InconvÃ©nients** : Peut Ãªtre trÃ¨s lÃ¢che

**Nearest Neighbor** :
- **Principe** : Construction gloutonne, toujours choisir la ville la plus proche
- **Avantages** : TrÃ¨s rapide, donne une solution complÃ¨te
- **InconvÃ©nients** : Non-admissible, peut Ãªtre trÃ¨s sous-optimale

### 5. Heuristiques apprises et adaptatifs

#### Heuristiques neuronales

```mermaid
graph LR
    A["Ã‰tat du problÃ¨me"] --> B["RÃ©seau de neurones"]
    B --> C["Estimation h(n)"]
    C --> D["Guidage A*"]
    D --> E["Feedback performance"]
    E --> B
```

**Avantages** :
- S'adaptent au domaine
- Peuvent capturer des patterns complexes
- GÃ©nÃ©ralisent Ã  partir d'expÃ©rience

**InconvÃ©nients** :
- Pas de garantie d'admissibilitÃ©
- NÃ©cessitent donnÃ©es d'entraÃ®nement
- CoÃ»t computationnel Ã©levÃ©

### 6. MÃ©triques et Ã©valuation des heuristiques

#### Facteur de branchement effectif

```mermaid
graph TD
    A[Mesure qualitÃ© heuristique] --> B[Effective Branching Factor]
    B --> C["b* tel que 1+b*+b*Â²+...+b* exposant d = N"]
    C --> D["N = nÅ“uds dÃ©veloppÃ©s<br/>d = profondeur solution"]
```

**InterprÃ©tation** :
- b* proche de 1 : excellente heuristique
- b* = b (facteur rÃ©el) : heuristique inutile
- Permet comparaison objective

#### Dominance heuristique

```mermaid
graph LR
    A["hâ‚ domine hâ‚‚"] --> B["si âˆ€n: hâ‚(n) â‰¥ hâ‚‚(n)"]
    B --> C["et hâ‚, hâ‚‚ admissibles"]
    C --> D["âŸ¹ hâ‚ dÃ©veloppe â‰¤ nÅ“uds que hâ‚‚"]
```

### 7. Conception pratique d'heuristiques

#### MÃ©thode de relaxation

```mermaid
flowchart TD
    A[ProblÃ¨me original] --> B[Identifier contraintes]
    B --> C[Supprimer contraintes]
    C --> D[RÃ©soudre problÃ¨me relaxÃ©]
    D --> E[Solution = heuristique]
```

**Exemple 8-puzzle** :
- Contrainte : une seule tuile peut bouger Ã  la fois
- Relaxation : toutes les tuiles peuvent "tÃ©lÃ©porter"
- Heuristique : somme des distances Manhattan

#### Pattern Databases

```mermaid
graph TD
    A[ProblÃ¨me complet] --> B[Extraire sous-problÃ¨me]
    B --> C[RÃ©soudre exhaustivement]
    C --> D[Stocker solutions]
    D --> E[Lookup pendant recherche]
```

**Avantages** :
- Heuristiques trÃ¨s prÃ©cises
- Admissibles par construction
- ParallÃ©lisables

**InconvÃ©nients** :
- MÃ©moire importante
- Temps de prÃ©-calcul
- LimitÃ© aux sous-problÃ¨mes

### 3. Optimisations de A*

#### A* bidirectionnel
- Recherche simultanÃ©e depuis le dÃ©but et la fin
- Rencontre au milieu
- ComplexitÃ© rÃ©duite de O(b^d) Ã  O(b^(d/2))

#### IDA* (Iterative Deepening A*)
- Combine les avantages de la recherche en profondeur et A*
- MÃ©moire linÃ©aire, optimalitÃ© prÃ©servÃ©e

### A* bidirectionnel et IDA* â€” quand les utiliser

- A* bidirectionnel : utile quand on peut rechercher depuis le dÃ©but et la fin et combiner les frontiÃ¨res. RÃ©duit souvent le coÃ»t exponentiel en profondeur.
- IDA* : appliquer des limites successives sur f (g+h) et faire une profondeur limitÃ©e. IdÃ©al quand la mÃ©moire est contrainte mais que h est informative.

---

## ğŸ”ï¸ Quand le problÃ¨me est trop gros : La recherche locale

Jusqu'ici, nous avons vu des algorithmes qui **explorent mÃ©thodiquement** pour trouver la solution parfaite. Mais que faire quand le problÃ¨me est **gigantesque** ?

### ğŸ¤¯ Le dÃ©fi des gros problÃ¨mes

**Imaginez que vous devez organiser un planning pour :**
- ğŸ¥ 100 mÃ©decins dans un hÃ´pital
- ğŸ“… Sur 365 jours  
- â° Avec 1000 contraintes diffÃ©rentes

**Le nombre de possibilitÃ©s ?** Plus que le nombre d'atomes dans l'univers ! ğŸŒŒ

**Avec BFS/DFS/A*** : Votre ordinateur mettrait des milliards d'annÃ©es â³
**Solution** : Changer complÃ¨tement de stratÃ©gie ! ğŸ’¡

---

## ğŸ¯ Nouvelle stratÃ©gie : "AmÃ©liorer au lieu d'explorer"

**L'idÃ©e rÃ©volutionnaire :** Au lieu de partir de zÃ©ro et tout explorer, on va :

1. ğŸ² **Commencer avec une solution "pas terrible"** (mais qui marche)
2. ğŸ”§ **L'amÃ©liorer petit Ã  petit** 
3. ğŸ¯ **S'arrÃªter quand c'est assez bien**

```mermaid
graph LR
    subgraph "ğŸ—ºï¸ Ancienne mÃ©thode (exploration)"
        A1[ğŸš© DÃ©part] --> B1[Explorer TOUT]
        B1 --> C1[â­ Solution parfaite]
    end
    
    subgraph "ğŸ”ï¸ Nouvelle mÃ©thode (amÃ©lioration locale)"
        A2[ğŸ² Solution alÃ©atoire] --> B2[AmÃ©liorer petit Ã  petit]
        B2 --> C2[âœ… TrÃ¨s bonne solution]
    end
    
    style C2 fill:#c8e6c9
```

---

## ğŸ”ï¸ Algorithme 1 : L'escalade de montagne (Hill Climbing)

### ğŸ§— L'analogie de l'alpiniste aveugle

**Imaginez que vous Ãªtes un alpiniste dans le brouillard** ğŸŒ«ï¸

```mermaid
graph TD
    subgraph "â›°ï¸ Montagne dans le brouillard"
        A["ğŸ§— Vous Ãªtes ici<br/>Altitude: 1500m"] 
        A --> B["ğŸ‘ˆ Gauche: 1400m"]
        A --> C["ğŸ‘† Haut: 1600m"]
        A --> D["ğŸ‘‰ Droite: 1480m"]
        A --> E["ğŸ‘‡ Bas: 1450m"]
    end
```

**Votre stratÃ©gie "Hill Climbing" :**
1. ğŸ” Regarder autour de vous (les voisins)
2. ğŸ“ˆ Choisir la direction qui monte le plus
3. ğŸš¶ Faire un pas dans cette direction  
4. ğŸ”„ RÃ©pÃ©ter jusqu'Ã  ne plus pouvoir monter

**Dans notre exemple :** Vous irez vers le HAUT (1600m) !

### ğŸ¯ Hill Climbing pour les problÃ¨mes d'optimisation

**Exemple concret : Organiser un planning d'hÃ´pital**

```mermaid
flowchart TD
    A["ğŸ“‹ Planning initial<br/>Score: 60/100<br/>ğŸ˜’ Beaucoup de problÃ¨mes"] --> B[ğŸ”„ Essayer petits changements]
    B --> C["ğŸ“‹ Planning modifiÃ©<br/>Score: 75/100<br/>ğŸ˜Š Un peu mieux !"]
    C --> D[ğŸ”„ Continuer Ã  amÃ©liorer]
    D --> E["ğŸ“‹ Planning final<br/>Score: 90/100<br/>ğŸ˜„ TrÃ¨s bien !"]
```

**Les "voisins" dans un planning :**
- Ã‰changer 2 mÃ©decins de service  
- DÃ©caler un service d'une heure
- Changer les jours de congÃ©

### âœ… Avantages de Hill Climbing

- **ğŸš€ TrÃ¨s rapide** : Pas besoin d'explorer tout
- **ğŸ§  Peu de mÃ©moire** : Garde juste la solution actuelle  
- **ğŸ”§ Simple Ã  programmer** : Logique intuitive
- **ğŸ“Š Marche bien en pratique** : Donne souvent de bons rÃ©sultats

### âŒ Le gros problÃ¨me : Les "faux sommets"

```mermaid
graph TD
    subgraph "ğŸ”ï¸ Paysage montagneux"
        A["ğŸ§— Vous Ãªtes ici<br/>Petit sommet: 1800m"] 
        A --> B[ğŸ‘ˆ 1700m â¬‡ï¸]
        A --> C[ğŸ‘‰ 1750m â¬‡ï¸] 
        A --> D[ğŸ‘† 1750m â¬‡ï¸]
        A --> E[ğŸ‘‡ 1700m â¬‡ï¸]
        
        F[ğŸ”ï¸ VRAI sommet<br/>3000m - Mais loin !]
    end
    
    style A fill:#ffeb3b
    style F fill:#4caf50
```

**Le drame :** Vous Ãªtes bloquÃ© sur un petit sommet ! Tous les voisins sont plus bas, donc Hill Climbing s'arrÃªte. Mais le VRAI sommet est ailleurs ! ğŸ˜±

**Ce problÃ¨me s'appelle :** "Optimum local" vs "Optimum global"

---

## ğŸ”¥ Algorithme 2 : Le refroidissement du mÃ©tal (Simulated Annealing)

### ğŸ”§ L'analogie du forgeron

**Imaginez un forgeron qui fabrique une Ã©pÃ©e** âš”ï¸

```mermaid
flowchart LR
    A[ğŸ”¥ MÃ©tal trÃ¨s chaud<br/>TrÃ¨s mallÃ©able] --> B[ğŸŒ¡ï¸ Refroidissement lent]
    B --> C[â„ï¸ MÃ©tal froid<br/>Forme finale parfaite]
```

**Le secret du forgeron :**
- **ğŸ”¥ DÃ©but (chaud) :** Le mÃ©tal peut faire de GROS changements de forme
- **ğŸŒ¡ï¸ Milieu (tiÃ¨de) :** Le mÃ©tal fait des changements moyens
- **â„ï¸ Fin (froid) :** Le mÃ©tal ne bouge presque plus, forme finale !

### ğŸ² Simulated Annealing : L'alpiniste intelligent

**Reprenons notre alpiniste, mais cette fois il est malin !**

```mermaid
graph TD
    subgraph "ğŸ”ï¸ StratÃ©gie intelligente"
        A[ğŸ§— Petit sommet<br/>ğŸŒ¡ï¸ TempÃ©rature: CHAUDE] --> B{ğŸ² Descendre malgrÃ© tout ?}
        B -->|ğŸ”¥ Oui! TempÃ©rature chaude<br/>J'ose prendre des risques| C[â¬‡ï¸ Je descends volontairement]
        C --> D[ğŸš¶ Je trouve un chemin<br/>vers le vrai sommet !]
        
        B -->|â„ï¸ Non, tempÃ©rature froide<br/>Je reste sage| E[ğŸ”ï¸ Je reste au sommet actuel]
    end
```

**La rÃ¨gle magique de Simulated Annealing :**

1. **ğŸ”¥ Au dÃ©but (tempÃ©rature chaude) :** J'accepte facilement les mauvaises dÃ©cisions
2. **ğŸŒ¡ï¸ Au milieu (tempÃ©rature tiÃ¨de) :** J'accepte parfois les mauvaises dÃ©cisions  
3. **â„ï¸ Ã€ la fin (tempÃ©rature froide) :** Je n'accepte presque que les bonnes dÃ©cisions

### ğŸ¯ Pourquoi Ã§a marche mieux ?

**Hill Climbing classique :**
```
ğŸ˜’ BloquÃ© sur le premier petit sommet trouvÃ©
```

**Simulated Annealing :**  
```
ğŸ˜Š Explore plus largement au dÃ©but, puis se stabilise sur un bon sommet
```

**Exemple de "tempÃ©rature" :**
- **ğŸ”¥ DÃ©but :** 80% de chance d'accepter une mauvaise dÃ©cision
- **ğŸŒ¡ï¸ Milieu :** 30% de chance d'accepter une mauvaise dÃ©cision
- **â„ï¸ Fin :** 5% de chance d'accepter une mauvaise dÃ©cision

---

## ğŸ§¬ Algorithme 3 : L'Ã©volution naturelle (Algorithmes GÃ©nÃ©tiques)

### ğŸ¦ L'analogie de Darwin

**Imaginez une Ã®le avec des lÃ©zards** ğŸ¦

```mermaid
graph TD
    subgraph "ğŸï¸ Ã‰volution des lÃ©zards"
        A[ğŸ‘¥ Population initiale<br/>LÃ©zards variÃ©s] --> B[ğŸ† SÃ©lection<br/>Les meilleurs survivent]
        B --> C[ğŸ‘¶ Reproduction<br/>BÃ©bÃ©s = mÃ©lange parents]
        C --> D[ğŸ² Mutations<br/>Quelques changements alÃ©atoires]
        D --> E[ğŸ‘¥ Nouvelle gÃ©nÃ©ration<br/>Encore mieux adaptÃ©e !]
        E --> B
    end
```

**Le processus d'Ã©volution :**
1. **ğŸ‘¥ Population** : Plein de lÃ©zards diffÃ©rents
2. **ğŸ† SÃ©lection** : Ceux qui courent le plus vite survivent
3. **ğŸ‘¶ Reproduction** : Les survivants font des bÃ©bÃ©s  
4. **ğŸ² Mutation** : Parfois un bÃ©bÃ© a une nouveautÃ© (queue plus longue, etc.)
5. **ğŸ”„ RÃ©pÃ©tition** : Au bout de 100 gÃ©nÃ©rations â†’ super-lÃ©zards !

### ğŸ¯ Algorithmes GÃ©nÃ©tiques pour l'optimisation

**Exemple : Optimiser un planning d'hÃ´pital**

```mermaid
flowchart TD
    A[ğŸ‘¥ 100 plannings alÃ©atoires<br/>ğŸ“Š Scores: 30 Ã  70/100] --> B[ğŸ† Garder les 20 meilleurs]
    B --> C[ğŸ‘¶ CrÃ©er 80 nouveaux plannings<br/>en mÃ©langeant les bons]
    C --> D[ğŸ² Ajouter quelques changements<br/>alÃ©atoires]
    D --> E[ğŸ‘¥ Nouvelle gÃ©nÃ©ration<br/>ğŸ“Š Scores: 50 Ã  85/100]
    E --> F{Assez bon ?}
    F -->|Non| B
    F -->|Oui| G[ğŸ‰ Meilleur planning trouvÃ© !]
```

**Comment "mÃ©langer" deux plannings :**
- **Planning Papa** : Docteur A le matin, Docteur B l'aprÃ¨s-midi
- **Planning Maman** : Docteur C le matin, Docteur A l'aprÃ¨s-midi  
- **Planning BÃ©bÃ©** : Docteur A le matin, Docteur A l'aprÃ¨s-midi

### âœ… Pourquoi les Algorithmes GÃ©nÃ©tiques sont puissants

- **ğŸŒ Exploration globale** : La population explore plein d'endroits diffÃ©rents
- **ğŸ§¬ Innovation** : Les mutations crÃ©ent des solutions inattendues
- **ğŸ† AmÃ©lioration continue** : Chaque gÃ©nÃ©ration est mieux que la prÃ©cÃ©dente
- **ğŸ”„ Robustesse** : Marche mÃªme si on ne comprend pas le problÃ¨me

---

## ğŸ¤” Quand utiliser quoi ?

### ğŸ¯ Choisir sa stratÃ©gie selon la situation

| Situation | Algorithme recommandÃ© | Pourquoi ? |
|-----------|----------------------|------------|
| ğŸ§© **Petit problÃ¨me** | BFS/DFS/A* | On peut explorer complÃ¨tement |
| ğŸ¢ **Gros problÃ¨me, besoin du parfait** | A* + bonne heuristique | Optimal mais plus lent |
| âš¡ **Gros problÃ¨me, vite fait** | Hill Climbing | Ultra rapide |
| ğŸ¯ **Gros problÃ¨me, bonne qualitÃ©** | Simulated Annealing | Bon compromis |
| ğŸŒ **ProblÃ¨me trÃ¨s complexe** | Algorithmes GÃ©nÃ©tiques | Exploration globale |

### ğŸ’¡ Conseils pratiques

1. **ğŸš€ Commencez simple** : Hill Climbing d'abord !
2. **ğŸ“Š Mesurez** : Comparez les rÃ©sultats de diffÃ©rents algorithmes
3. **ğŸ² Testez plusieurs fois** : Les algorithmes alÃ©atoires donnent des rÃ©sultats variables
4. **ğŸ”„ Combinez** : Utilisez Simulated Annealing + Hill Climbing pour finir

---

### ğŸ’» Version technique pour les curieux

## Recherche locale et mÃ©ta-heuristiques

### 1. Recherche par montÃ©e de gradient (Hill Climbing)

**Principe** : Ã€ chaque Ã©tape, choisir le voisin qui amÃ©liore le plus la fonction objectif.

**ProblÃ¨mes** :
- **Maxima locaux** : Solutions sous-optimales dont tous les voisins sont pires
- **Plateaux** : Zones plates sans gradient clair
- **CrÃªtes** : Optimum accessible seulement par une sÃ©quence d'actions

**Variantes** :
- **MontÃ©e stochastique** : Choix alÃ©atoire parmi les amÃ©liorations
- **Premier choix** : Prendre la premiÃ¨re amÃ©lioration trouvÃ©e
- **RedÃ©marrage alÃ©atoire** : Plusieurs exÃ©cutions depuis des points diffÃ©rents

### 2. Recuit simulÃ© (Simulated Annealing)

InspirÃ© du processus physique de refroidissement des mÃ©taux.

**Principe** : Accepter parfois des solutions dÃ©gradantes avec une probabilitÃ© dÃ©croissante.

**Fonction de probabilitÃ©** :
```
P(accepter) = exp(Î”E / T)
```
oÃ¹ Î”E = diffÃ©rence d'Ã©nergie, T = tempÃ©rature

**Programme de refroidissement** :
```
T(t) = Tâ‚€ Ã— Î±^t   (refroidissement gÃ©omÃ©trique)
ou
T(t) = Tâ‚€ / (1 + Î±t)   (refroidissement logarithmique)
```

### Diagramme Simulated Annealing

```mermaid
flowchart TD
    Start(["Init solution S0"]) --> Eval{"Eval f(S)"}
    Eval --> Iterate["Pour t = 1..T"]
    Iterate --> Neighbor["Ã‰chantillonner voisin S'"]
    Neighbor --> Delta["Î” = f(S') - f(S)"]
    Delta --> Decide{"Î” < 0 ?"}
    Decide -->|oui| Accept["Accepter S <- S'"]
    Decide -->|non| Prob["Accepter avec prob exp(-Î”/T)"]
    Prob --> UpdateT["Mettre Ã  jour T"]
    UpdateT --> Iterate
    Iterate --> Done["Retourner meilleure solution"]
```

Conseils pratiques :
- Initialiser T0 de maniÃ¨re Ã  accepter ~80% des mauvais mouvements au dÃ©part (rÃ¨gle empirique), puis rÃ©duire lentement.
- Choisir un voisinage (2-opt pour TSP, swap pour permutations) adaptÃ© au problÃ¨me.
- RÃ©pÃ©ter plusieurs redÃ©marrages pour amÃ©liorer la robustesse.

### 3. Algorithmes gÃ©nÃ©tiques

**Population** : Ensemble de solutions candidates
**SÃ©lection** : Choisir les meilleurs individus pour reproduction
**Croisement** : Combiner deux parents pour crÃ©er des descendants
**Mutation** : Modifications alÃ©atoires pour maintenir la diversitÃ©

**Algorithme principal** :
```
population = initialiser_population()
rÃ©pÃ©ter:
    Ã©valuer_fitness(population)
    parents = sÃ©lectionner(population)
    descendants = croiser_et_muter(parents)
    population = sÃ©lectionner_survivants(parents + descendants)
jusqu'Ã  critÃ¨re_arrÃªt
```

```mermaid
flowchart TB
    A[Initialiser population] --> B[Ã‰valuer fitness]
    B --> C[SÃ©lection parents]
    C --> D[Crossover]
    D --> E[Mutation]
    E --> F[SÃ©lection survivants]
    F --> G{critÃ¨re atteint ?}
    G -->|non| B
    G -->|oui| H[Sortie meilleure solution]
```

Bonnes pratiques :
- Encodage : choisissez binaire, vecteur, ou permutation selon le problÃ¨me (TSP â†’ permutation).
- OpÃ©rateurs : pour permutations utiliser PMX / OX / CX ; pour vecteurs rÃ©els utiliser BLX-Î± ou SBX.
- ParamÃ¨tres : taille de population, taux de crossover/mutation, mÃ©thode de sÃ©lection (tournament/roulette) ont un fort impact.

Astuce : combiner un GA avec une recherche locale (memetic algorithm) : appliquer 2-opt sur les meilleurs individus Ã  chaque gÃ©nÃ©ration.

---

## ğŸ² Jouer contre un adversaire intelligent

Jusqu'ici, nous avons rÃ©solu des problÃ¨mes **"en solo"** : trouver un chemin, rÃ©soudre un puzzle, optimiser un planning.

Mais que faire quand il faut jouer **contre quelqu'un d'autre** qui essaie de vous battre ? ğŸ¤”

### ğŸ†š Le nouveau dÃ©fi : L'adversaire intelligent

**Imaginez que vous jouez aux Ã©checs** â™Ÿï¸

```mermaid
graph LR
    subgraph "ğŸ¤– Vous (ordinateur)"
        A[ğŸ§  Je rÃ©flÃ©chis Ã  mon coup] --> B[ğŸ¯ Je veux GAGNER]
    end
    
    subgraph "ğŸ‘¤ Adversaire (humain)"  
        C[ğŸ§  Il rÃ©flÃ©chit Ã  son coup] --> D[ğŸ¯ Il veut GAGNER aussi !]
    end
    
    B -.-> D
    D -.-> B
    
    style B fill:#c8e6c9
    style D fill:#ffcdd2
```

**La diffÃ©rence cruciale :**
- âœ… **ProblÃ¨me normal** : L'environnement est passif (la grille ne bouge pas toute seule)
- ğŸ†š **Jeu adversarial** : L'adversaire **rÃ©agit** Ã  vos coups et essaie de vous contrer !

### ğŸ§© La stratÃ©gie rÃ©volutionnaire : "Penser comme l'adversaire"

**L'astuce gÃ©niale de Minimax :**

```mermaid
flowchart TD
    A[ğŸ¤– Mon tour] --> B[ğŸ¤” Si je joue ce coup...]
    B --> C[ğŸ‘¤ Que ferait l'adversaire ?<br/>Il choisira son MEILLEUR coup]
    C --> D[ğŸ¤– Et aprÃ¨s, que ferais-je ?<br/>Je choisirai MON meilleur coup]
    D --> E[ğŸ‘¤ Et lui aprÃ¨s ?<br/>SON meilleur coup]
    E --> F[ğŸ¯ Au final : qui gagne ?]
```

**L'idÃ©e :** Simuler plusieurs coups Ã  l'avance en supposant que l'adversaire joue **parfaitement** !

---

## ğŸ¯ Minimax : L'algorithme du parfait stratÃ¨ge

### ğŸ® L'analogie simple : Le tic-tac-toe

**Regardons un exemple concret avec tic-tac-toe :**

```mermaid
graph TD
    subgraph "ğŸ® Position actuelle"
        A["âŒ _ â­•<br/>_ âŒ _<br/>â­• _ _<br/><br/>ğŸ¤– Mon tour (âŒ)"]
    end
    
    A --> B["Coup 1: En haut milieu"]
    A --> C["Coup 2: Au milieu droite"]  
    A --> D["Coup 3: En bas milieu"]
    
    B --> B1["âŒ âŒ â­•<br/>_ âŒ _<br/>â­• _ _<br/><br/>ğŸ‘¤ L'adversaire joue..."]
    C --> C1["âŒ _ â­•<br/>_ âŒ â­•<br/>â­• _ _<br/><br/>ğŸ‘¤ L'adversaire joue..."]
    D --> D1["âŒ _ â­•<br/>_ âŒ _<br/>â­• âŒ _<br/><br/>ğŸ‘¤ L'adversaire joue..."]
```

**Minimax va calculer :**
- Pour chaque coup possible â†’ Qu'est-ce que l'adversaire ferait ?
- Pour chaque rÃ©ponse de l'adversaire â†’ Qu'est-ce que je ferais ?
- Et ainsi de suite jusqu'Ã  la fin de la partie
- **RÃ©sultat final :** Victoire/DÃ©faite/Match nul

### ğŸ† L'algorithme en action

```mermaid
flowchart TD
    A[ğŸ¤– MON tour<br/>Je veux MAXIMISER mes chances] --> B[ğŸ‘¤ SON tour<br/>Il va MINIMISER mes chances]
    B --> C[ğŸ¤– MON tour<br/>Je veux MAXIMISER mes chances]
    C --> D[ğŸ‘¤ SON tour<br/>Il va MINIMISER mes chances]
    D --> E[ğŸ Fin de partie<br/>Qui gagne ?]
    
    style A fill:#c8e6c9
    style C fill:#c8e6c9
    style B fill:#ffcdd2
    style D fill:#ffcdd2
```

**Le nom "Minimax" vient de :**
- **MAX** : Mes tours â†’ je veux **MAXimiser** mon score
- **MIN** : Ses tours â†’ il va **MINimiser** mon score

### ğŸ¯ Comment Ã©valuer "qui gagne" ?

**Pour des jeux simples (tic-tac-toe) :**
- âœ… **Je gagne** = +1 point
- âŒ **Je perds** = -1 point  
- ğŸ¤ **Match nul** = 0 point

**Pour des jeux complexes (Ã©checs) :**
- ğŸ° **Valeur des piÃ¨ces** : Reine=9, Tour=5, Fou=3, etc.
- ğŸ¯ **Position** : ContrÃ´le du centre = bonus
- ğŸ‘‘ **SÃ©curitÃ© du roi** : Roi en danger = malus
- **Score total** = Mes points - Ses points

### âœ… Pourquoi Minimax est gÃ©nial

- **ğŸ† StratÃ©gie optimale** : Joue le meilleur coup possible (thÃ©oriquement)
- **ğŸ”® Vision Ã  long terme** : Pense plusieurs coups Ã  l'avance
- **ğŸ§  Intelligence** : Comprend les plans de l'adversaire
- **ğŸ“Š Mesurable** : Peut calculer prÃ©cisÃ©ment qui a l'avantage

### âŒ Le gros problÃ¨me : L'explosion combinatoire

**Exemple concret avec les Ã©checs :**

```mermaid
graph TD
    A["ğŸ Position actuelle<br/>35 coups possibles"] --> B["ğŸ“Š Profondeur 1<br/>35 positions"]
    B --> C["ğŸ“Š Profondeur 2<br/>35 x 35 = 1,225 positions"]
    C --> D["ğŸ“Š Profondeur 3<br/>35Â³ = 42,875 positions"]
    D --> E["ğŸ“Š Profondeur 10<br/>35Â¹â° = 2,758,547,353,515,625 positions"]
    E --> F["ğŸ˜± Plus que l'Ã¢ge de l'univers !"]
```

**Solution :** Limiter la profondeur + utiliser des techniques d'optimisation !

---

## âš¡ Alpha-Beta : L'optimisation intelligente

### âœ‚ï¸ L'astuce pour aller plus vite

**L'idÃ©e gÃ©niale :** Ã‰viter de calculer les branches "inutiles" !

```mermaid
graph TD
    subgraph "ğŸŒ³ Arbre de jeu"
        A[ğŸ¤– Mon tour] --> B[Option A]
        A --> C[Option B]
        A --> D[Option C]
        
        B --> E[ğŸ‘¤ Sa rÃ©ponse 1<br/>Score: -5]
        B --> F[ğŸ‘¤ Sa rÃ©ponse 2<br/>Score: -3]
        
        C --> G[ğŸ‘¤ Sa rÃ©ponse 1<br/>Score: -2]
        C --> H[ğŸ‘¤ Sa rÃ©ponse 2<br/>âŒ Pas besoin de calculer !]
    end
```

**Le raisonnement :**
1. Option A â†’ Au mieux je score -3
2. Option B â†’ J'ai dÃ©jÃ  -2, c'est mieux que -3
3. **Donc pas besoin de finir de calculer Option A !** âœ‚ï¸

### ğŸš€ Gain de performance spectaculaire

**Sans Alpha-Beta :** Explorer 1,000,000 de positions
**Avec Alpha-Beta :** Explorer seulement 10,000 positions
**Gain :** 100 fois plus rapide ! ğŸš€

---

## ğŸ® Applications concrÃ¨tes

### ğŸ† SuccÃ¨s historiques

- **ğŸ”µ Deep Blue (1997)** : Premier ordinateur Ã  battre un champion du monde d'Ã©checs
- **ğŸ”´ AlphaGo (2016)** : MaÃ®trise du jeu de Go, considÃ©rÃ© impossible avant
- **ğŸ® Jeux vidÃ©o** : IA des NPCs dans les jeux de stratÃ©gie

### ğŸ’¡ Utilisations modernes

- **ğŸ¯ Planification militaire** : Anticiper les mouvements ennemis
- **ğŸ’¼ StratÃ©gie d'entreprise** : PrÃ©voir les rÃ©actions des concurrents  
- **ğŸ¤– NÃ©gociation automatique** : SystÃ¨mes qui nÃ©gocient des contrats
- **ğŸ² Poker IA** : Jouer avec des informations incomplÃ¨tes

---

### ğŸ’» Version technique pour les curieux

## Jeux et recherche adversariale

### 1. Algorithme Minimax - Analyse approfondie

```mermaid
flowchart TD
    A[Minimax Algorithm] --> B[Principe]
    A --> C[Structure arbre]
    A --> D[Ã‰valuation]
    
    B --> B1[Joueur MAX: maximise<br/>Joueur MIN: minimise<br/>Alternance niveaux]
    C --> C1[NÅ“uds MAX<br/>NÅ“uds MIN<br/>Feuilles: Ã©valuation]
    D --> D1[Bottom-up<br/>Propagation valeurs<br/>DÃ©cision racine]
    
    style A fill:#e8f5e8
    style D1 fill:#fff3e0
```

**Principe dÃ©taillÃ©** : Exploration exhaustive d'un arbre de jeu en supposant que l'adversaire joue optimalement.

**Avantages spÃ©cifiques** :

- **OptimalitÃ© thÃ©orique** : Garantit le meilleur coup possible contre adversaire optimal
- **SimplicitÃ© conceptuelle** : Logique rÃ©cursive naturelle et intuitive
- **ComplÃ©tude** : Explore toutes les possibilitÃ©s jusqu'Ã  la profondeur limite
- **DÃ©terminisme** : RÃ©sultat reproductible pour Ã©tat donnÃ©

**InconvÃ©nients et limitations** :

- **Explosion combinatoire** : O(b^d) devient rapidement intraitable
- **HypothÃ¨se forte** : Assume que l'adversaire joue parfaitement
- **Profondeur limitÃ©e** : Doit tronquer l'arbre, Ã©valuation approximative
- **Pas d'apprentissage** : Ne s'amÃ©liore pas avec l'expÃ©rience

**ComplexitÃ© dÃ©taillÃ©e** :

```mermaid
graph TD
    A[ComplexitÃ© Minimax] --> B["Temps: O(b exposant d)"]
    A --> C["Espace: O(b x d)"]
    A --> D[Exemples pratiques]
    
    D --> D1["Tic-tac-toe: b=9, d=9<br/>â‰ˆ 300,000 nÅ“uds"]
    D --> D2["Ã‰checs: bâ‰ˆ35, d=10<br/>â‰ˆ 3 x 10^15 nÅ“uds"]
    D --> D3["Go: bâ‰ˆ361, d=361<br/>Impossible sans pruning"]
```

**Cas d'usage optimaux** :

- **Jeux parfaits petits** : Tic-tac-toe, Connect 4, Othello (profondeur rÃ©duite)
- **Fins de partie** : Ã‰checs avec peu de piÃ¨ces (tableaux de finale)
- **Puzzles adversariaux** : Nim, Hex avec Ã©tats limitÃ©s
- **Validation thÃ©orique** : Prouver optimalitÃ© dans jeux simples

**ImplÃ©mentation optimisÃ©e** :

```python
def minimax_optimized(state, depth, maximizing_player, memo={}):
    # MÃ©moÃ¯zation pour Ã©viter recalculs
    state_key = (state.hash(), depth, maximizing_player)
    if state_key in memo:
        return memo[state_key]
    
    if depth == 0 or state.is_terminal():
        value = state.evaluate()
        memo[state_key] = value
        return value
    
    if maximizing_player:
        max_eval = float('-inf')
        for move in state.get_legal_moves():
            new_state = state.make_move(move)
            eval_score = minimax_optimized(new_state, depth-1, False, memo)
            max_eval = max(max_eval, eval_score)
        memo[state_key] = max_eval
        return max_eval
    else:
        min_eval = float('inf')
        for move in state.get_legal_moves():
            new_state = state.make_move(move)
            eval_score = minimax_optimized(new_state, depth-1, True, memo)
            min_eval = min(min_eval, eval_score)
        memo[state_key] = min_eval
        return min_eval
```

### 2. Ã‰lagage Alpha-BÃªta - Analyse approfondie

```mermaid
flowchart TD
    A[Alpha-Beta Pruning] --> B[Principe]
    A --> C[MÃ©canisme]
    A --> D[Optimisation]
    
    B --> B1["alpha: meilleur pour MAX<br/>beta: meilleur pour MIN<br/>Ã‰lagage si alpha â‰¥ beta"]
    C --> C1[Propagation bornes<br/>Test Ã  chaque nÅ“ud<br/>Coupe branches inutiles]
    D --> D1[Move ordering<br/>Transposition tables<br/>Aspiration windows]
    
    style A fill:#e3f2fd
    style D1 fill:#fff8e1
```

**Principe dÃ©taillÃ©** : Optimisation de minimax qui Ã©vite l'exploration de branches qui ne peuvent pas influencer le rÃ©sultat final.

**Avantages spÃ©cifiques** :

- **RÃ©duction drastique** : O(b^(d/2)) dans le meilleur cas vs O(b^d)
- **MÃªme rÃ©sultat** : Identique Ã  minimax, juste plus efficace
- **Applicable partout** : Peut Ãªtre ajoutÃ© Ã  tout algorithme minimax
- **AmÃ©lioration garantie** : Jamais pire que minimax standard

**MÃ©canisme dÃ©taillÃ©** :

```mermaid
sequenceDiagram
    participant MAX as NÅ“ud MAX
    participant MIN as NÅ“ud MIN
    participant LEAF as Feuille
    
    MAX->>MIN: Î± = -âˆ, Î² = +âˆ
    MIN->>LEAF: Ã‰value premier enfant
    LEAF-->>MIN: Valeur = 5
    MIN->>MIN: Î² = min(Î², 5) = 5
    MIN->>LEAF: Ã‰value second enfant
    LEAF-->>MIN: Valeur = 2
    MIN->>MIN: Î² = min(5, 2) = 2
    MAX->>MAX: Î± = max(Î±, 2) = 2
    Note over MAX: Si prochain MIN trouve â‰¥ 2, Ã©lagage!
```

**Facteurs d'efficacitÃ©** :

- **Ordre des mouvements** : Crucial pour performance
- **Profondeur paire/impaire** : Affecte qualitÃ© des coupes
- **Largeur de l'arbre** : Plus b est grand, plus le gain est important

**Techniques d'amÃ©lioration** :

```python
# Move Ordering : Ã©valuer les meilleurs coups en premier
def order_moves(state, moves):
    scored_moves = []
    for move in moves:
        new_state = state.make_move(move)
        # Ã‰valuation rapide pour estimation
        score = quick_evaluate(new_state)
        scored_moves.append((score, move))
    
    # Trier par score dÃ©croissant pour MAX, croissant pour MIN
    return [move for score, move in sorted(scored_moves, reverse=state.is_max_turn())]

# Transposition Table : Ã©viter recalculs
class TranspositionTable:
    def __init__(self, size=1000000):
        self.table = {}
        self.size = size
    
    def store(self, state_hash, depth, value, flag):
        if len(self.table) >= self.size:
            # StratÃ©gie de remplacement : virer les anciens
            self.table.clear()
        self.table[state_hash] = (depth, value, flag)
    
    def lookup(self, state_hash, depth, alpha, beta):
        if state_hash not in self.table:
            return None
        stored_depth, value, flag = self.table[state_hash]
        if stored_depth >= depth:
            if flag == 'EXACT':
                return value
            elif flag == 'LOWERBOUND' and value >= beta:
                return value
            elif flag == 'UPPERBOUND' and value <= alpha:
                return value
        return None
```

**Variantes avancÃ©es** :

```mermaid
graph TD
    A[Alpha-Beta Variants] --> B[Principal Variation Search]
    A --> C[Negascout]
    A --> D[MTD-f]
    
    B --> B1[Recherche fenÃªtre nulle<br/>Re-recherche si nÃ©cessaire]
    C --> C1[Version simplifiÃ©e PVS<br/>Plus facile Ã  implÃ©menter]
    D --> D1[Memory-enhanced Test Driver<br/>Recherches successives]
```

### Comparaison performance Minimax vs Alpha-BÃªta

```mermaid
graph LR
    subgraph "Arbre exemple (b=3, d=3)"
        A[Racine] --> B1[MIN]
        A --> B2[MIN] 
        A --> B3[MIN]
        B1 --> C1[3]
        B1 --> C2[5]
        B1 --> C3[2]
        B2 --> C4[1]
        B2 --> C5[4]
        B2 --> C6[6]
        B3 --> C7[7]
        B3 --> C8[1]
        B3 --> C9[8]
    end
    
    subgraph "RÃ©sultats"
        D[Minimax: 27 nÅ“uds]
        E[Alpha-Beta: 15 nÅ“uds]
        F[Gain: 44%]
    end
```

**ProblÃ¨mes frÃ©quents et solutions** :

- **Mauvais ordering** : ImplÃ©menter killer moves, history heuristic
- **Overhead des coupes** : Ne pas activer sur arbres trÃ¨s petits
- **DÃ©bordement de pile** : ImplÃ©menter version itÃ©rative pour profondeurs importantes
- **Ã‰valuation coÃ»teuse** : Mettre en cache, Ã©valuation incrÃ©mentale

### Diagramme Minimax & Alpha-BÃªta

```mermaid
graph TD
    root[Ã‰tat initial]
    root --> a1[MAX]
    root --> b1[MAX]
    a1 --> a1a[MIN]
    a1 --> a1b[MIN]
    a1a --> a1a1[Feuille: 3]
    a1a --> a1a2[Feuille: 5]
    a1b --> a1b1[Feuille: 2]
    a1b --> a1b2[Feuille: 9]
    b1 --> b1a[MIN]
    b1 --> b1b[MIN]
    b1a --> b1a1[Feuille: 7]
    b1a --> b1a2[Feuille: 4]
```

Explication rapide : Alpha-BÃªta maintient deux bornes (Î± pour MAX, Î² pour MIN). Quand une branche ne peut amÃ©liorer la valeur actuelle du joueur courant (Î± â‰¥ Î²), on peut l'Ã©laguer.

## Applications pratiques

### 1. Navigation et robotique
- Planification de chemin pour robots autonomes
- Navigation GPS avec contraintes de trafic
- Ã‰vitement d'obstacles dynamiques

### 2. Jeux vidÃ©o
- IA des NPCs (comportements, pathfinding)
- GÃ©nÃ©ration procÃ©durale de contenu
- Ã‰quilibrage automatique de difficultÃ©

### 3. Optimisation industrielle
- Ordonnancement de production
- Allocation de ressources
- Optimisation de chaÃ®nes logistiques

### 4. Intelligence artificielle gÃ©nÃ©rale
- Planification automatique
- Raisonnement symbolique
- RÃ©solution de problÃ¨mes complexes

## DÃ©fis et perspectives

### Limitations actuelles
- **MalÃ©diction de la dimensionnalitÃ©** : Explosion combinatoire
- **Heuristiques domain-specific** : Difficiles Ã  gÃ©nÃ©raliser
- **Ã‰quilibre exploration/exploitation** : Compromis fondamental

### Directions futures
- **Apprentissage d'heuristiques** : RÃ©seaux de neurones pour guider la recherche
- **Recherche hybride** : Combinaison avec l'apprentissage par renforcement
- **ParallÃ©lisation** : Exploitation des architectures multi-cÅ“urs

## Exercices pratiques

1. **ImplÃ©mentation A*** : Programmer A* pour rÃ©soudre le 8-puzzle. ImplÃ©mentez au moins deux heuristiques (Hamming, Manhattan) et une variante avec Linear Conflict. Comparez : temps CPU, nombre de nÅ“uds dÃ©veloppÃ©s, longueur de solution.
2. **Comparaison empirique** : Mesurer (temps, mÃ©moire, nÅ“uds explorÃ©s) BFS vs DFS vs A* sur labyrinthes de tailles croissantes. Fournir graphiques (taille vs nÅ“uds) et analyser les points de basculement.
3. **Conception d'heuristique** : Pour un robot sur grille avec diagonales, proposer deux heuristiques admissibles, montrer leur admissibilitÃ© et mesurer laquelle domine (dÃ©veloppe moins de nÅ“uds).
4. **Recuit simulÃ© (TSP)** : ImplÃ©menter voisinage 2-opt, tester plusieurs schedules (gÃ©omÃ©trique Î±=0.99, logarithmique), exÃ©cuter plusieurs semences et comparer meilleures distances trouvÃ©es.
5. **Algorithmes gÃ©nÃ©tiques (TSP)** : ImplÃ©menter encodage permutation, crossover PMX/OX, mutation swap/inversion. Comparer GA pur vs GA + 2-opt (memetic).
6. **Minimax & Alpha-BÃªta** : ImplÃ©menter minimax et alpha-beta pour tic-tac-toe ; mesurer le nombre de nÅ“uds visitÃ©s avec/without ordering heuristics.


## Annexes : Guides pratiques et comparaisons

### 1. Tableau de comparaison complet des algorithmes

```mermaid
graph TD
    A[Algorithmes de recherche] --> B[Non informÃ©s]
    A --> C[InformÃ©s]
    A --> D[Locaux]
    A --> E[Adversariaux]
    
    B --> B1["BFS: Optimal, O(b exposant d)<br/>DFS: MÃ©moire O(b x d)<br/>UCS: Optimal, coÃ»ts variÃ©s"]
    C --> C1["Greedy: Rapide, non optimal<br/>A*: Optimal, heuristique<br/>IDA*: MÃ©moire linÃ©aire"]
    D --> D1["Hill Climbing: Simple<br/>Simulated Annealing: Ã‰vite locaux<br/>Genetic: Population"]
    E --> E1["Minimax: Optimal thÃ©orique<br/>Alpha-Beta: Pruning efficace"]
```

| Algorithme | ComplÃ©tude | OptimalitÃ© | ComplexitÃ© Temps | ComplexitÃ© Espace | Usage typique |
|------------|------------|------------|------------------|-------------------|---------------|
| **BFS** | âœ… Oui | âœ… Oui (coÃ»t uniforme) | O(b exposant d) | O(b exposant d) | Puzzles peu profonds |
| **DFS** | âŒ Non (infini) | âŒ Non | O(b exposant m) | O(b x m) | Backtracking, Ã©numÃ©ration |
| **UCS** | âœ… Oui | âœ… Oui | O(b exposant C*/Îµ) | O(b exposant C*/Îµ) | CoÃ»ts non-uniformes |
| **Greedy** | âŒ Non | âŒ Non | O(b exposant m) | O(b exposant m) | Approximation rapide |
| **A*** | âœ… Oui | âœ… Oui (h admissible) | O(b exposant d) | O(b exposant d) | Navigation optimale |
| **IDA*** | âœ… Oui | âœ… Oui | O(b exposant d) | O(b x d) | MÃ©moire limitÃ©e |
| **Hill Climbing** | âŒ Non | âŒ Non | Variable | O(1) | Optimisation simple |
| **Simulated Annealing** | âŒ Non | ğŸ”„ Probabiliste | Variable | O(1) | Ã‰viter optima locaux |
| **Genetic Algorithm** | âŒ Non | âŒ Non | Variable | O(population) | Espaces complexes |
| **Minimax** | âœ… Oui | âœ… Oui (thÃ©orique) | O(b exposant d) | O(b x d) | Jeux parfaits |
| **Alpha-Beta** | âœ… Oui | âœ… Oui | O(b exposant d/2) | O(b x d) | Jeux avec pruning |

### 2. Guide de sÃ©lection d'algorithme

```mermaid
flowchart TD
    A[Choisir un algorithme] --> B{Type de problÃ¨me ?}
    
    B -->|Recherche chemin| C{CoÃ»t uniforme ?}
    B -->|Optimisation| D{Fonction continue ?}
    B -->|Jeu adversarial| E{Temps limitÃ© ?}
    
    C -->|Oui| F{Profondeur solution ?}
    C -->|Non| G[A* ou UCS]
    
    F -->|Faible| H[BFS]
    F -->|Ã‰levÃ©e| I{MÃ©moire limitÃ©e ?}
    
    I -->|Oui| J[IDA* ou DFS]
    I -->|Non| K[A*]
    
    D -->|Oui| L{Gradient disponible ?}
    D -->|Non| M[Genetic Algorithm]
    
    L -->|Oui| N[Gradient Descent]
    L -->|Non| O{Optima locaux ?}
    
    O -->|ProblÃ¨me| P[Simulated Annealing]
    O -->|OK| Q[Hill Climbing]
    
    E -->|Oui| R[Alpha-Beta + pruning]
    E -->|Non| S[Minimax complet]
```

### 3. Aide-mÃ©moire (Quick Reference)

#### Formules essentielles

- **A*** : f(n) = g(n) + h(n)
- **AdmissibilitÃ©** : h(n) â‰¤ h*(n) âˆ€n
- **Consistance** : h(n) â‰¤ c(n,a,n') + h(n') âˆ€n,a,n'
- **SA Acceptance** : P = exp(-Î”E/T)
- **Alpha-Beta** : Prune if Î± â‰¥ Î²

#### ComplexitÃ©s mÃ©morables

- BFS/A* : O(b exposant d) temps et espace
- DFS : O(b exposant m) temps, O(b x m) espace  
- Alpha-Beta : O(b exposant d/2) meilleur cas
- Hill Climbing : O(1) espace constant

#### Checklist de dÃ©bug

- [ ] Heuristique admissible et consistante ?
- [ ] DÃ©tection de cycles implÃ©mentÃ©e ?
- [ ] Structures de donnÃ©es efficaces ?
- [ ] ParamÃ¨tres rÃ©glÃ©s pour le domaine ?
- [ ] Tests sur cas simples validÃ©s ?

---

## Ressources complÃ©mentaires

- **Livres** : "Artificial Intelligence: A Modern Approach" (Russell & Norvig)
- **Cours en ligne** : CS188 UC Berkeley, MIT 6.034
- **ImplÃ©mentations** : BibliothÃ¨ques Python (NetworkX, DEAP)
- **CompÃ©titions** : ICAPS (International Conference on Automated Planning and Scheduling)

---

*Cette leÃ§on prÃ©sente les concepts fondamentaux de la recherche en IA. La maÃ®trise de ces algorithmes est essentielle pour comprendre de nombreux domaines de l'intelligence artificielle moderne.*

## Notebooks d'exercices

EntraÃ®nez-vous avec un carnet d'exercices contenant des gabarits "add your code here" :

- ImplÃ©menter BFS sur un graphe simple
- ImplÃ©menter A* sur une grille avec heuristique Manhattan
- Comparer empiriquement BFS/DFS/A* sur de petits graphes

AccÃ©der au notebook: /notebooks/03_recherche_optimisation_exercices.ipynb
